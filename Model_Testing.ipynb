{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet,SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score,accuracy_score,mean_absolute_error\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df.values.ravel() == -1).reshape(df.shape).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Trees')\n",
    "y = df['Trees']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_mse = ['Shrubs', 'Peren_FG', 'bare_groun', 'Annual_FG', 'vpdmax', 'tmean',\n",
    "       'slope', 'Runoff', 'Flooding_F', 'BD_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = df[best_feature_mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(best_df)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.99 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PCA(n_components=0.95)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numberof Principle Components:  9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9757100720377053"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Numberof Principle Components: \", pca.n_components_)  \n",
    "\n",
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651, 9)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Degree:  2\n"
     ]
    }
   ],
   "source": [
    "degreeList = [1,2,3,4,5,6]\n",
    "\n",
    "\n",
    "mse_train, mse_test = [], []\n",
    "\n",
    "for degree in degreeList:\n",
    "\n",
    "    model = make_pipeline(PolynomialFeatures(degree, include_bias=False), StandardScaler(), LinearRegression()) \n",
    "  \n",
    "    model.fit(X_train, y_train)\n",
    "       \n",
    "    # Make prediction \n",
    "    y_train_predicted = model.predict(X_train)\n",
    "    y_test_predicted = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    mse_train.append(mean_squared_error(y_train, y_train_predicted))\n",
    "    mse_test.append(mean_squared_error(y_test, y_test_predicted))\n",
    "   \n",
    "\n",
    "plt.figure(figsize=(10, 6))   \n",
    "plt.plot(degreeList, np.sqrt(mse_test), \"ro-\", alpha=1.0, linewidth=1.0, label=\"Test RMSE\")\n",
    "plt.plot(degreeList, np.sqrt(mse_train), \"bo-\", alpha=1.0, linewidth=1.0, label=\"Train RMSE\") \n",
    "plt.legend(loc=\"best\", fontsize=14) \n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"RMSE for Varying Degree\")\n",
    "plt.show()\n",
    "\n",
    "# Find the value of optimal degree for the polynomial that gives smallest RMSE\n",
    "\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "j = 0\n",
    "min_rmse = rmse_test[j]\n",
    "optimal_degree = 1\n",
    "\n",
    "for i in degreeList:\n",
    "    if(rmse_test[j] < min_rmse):\n",
    "        min_rmse = rmse_test[j]\n",
    "        optimal_degree = i\n",
    "    j +=1\n",
    "    \n",
    "print(\"\\nOptimal Degree: \", optimal_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable that speficies the degree of the polynomial to be added to the feature vector\n",
    "poly_degree = optimal_degree\n",
    "\n",
    "\n",
    "# Add polynomial terms with the feature vector using the sklearn PolynomialFeatures class\n",
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Original Features:  10\n",
      "No. of Augmented Features:  65\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of Original Features: \", X_train.shape[1])\n",
    "print(\"No. of Augmented Features: \", X_train_poly.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1316 tasks      | elapsed:    9.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (negative mean squared error): -31.456177\n",
      "Optimal Hyperparameter Values:  {'alpha': 0.9492307692307692, 'solver': 'sparse_cg'}\n",
      "\n",
      "\n",
      "Wall time: 18.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:   18.3s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "\n",
    "param_grid = {'alpha': np.linspace(0.01, 1.0, num=40), \n",
    "              'solver': [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"saga\"]}\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "ridge_cv = GridSearchCV(ridge, param_grid, scoring='neg_mean_squared_error', cv=10, verbose=1, n_jobs=-1)\n",
    "ridge_cv.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "params_optimal_ridge = ridge_cv.best_params_\n",
    "\n",
    "print(\"Best Score (negative mean squared error): %f\" % ridge_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_ridge)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha:  0.9492307692307692\n",
      "Optimal alpha:  sparse_cg\n",
      "\n",
      "----------------------------- Model Evaluation -----------------------------\n",
      "\n",
      "Mean squared error: 27.85\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "\n",
    "# Optimal model parameters\n",
    "ridge_alpha = ridge_cv.best_params_['alpha']\n",
    "print(\"Optimal alpha: \", ridge_alpha)\n",
    "\n",
    "ridge_solver = ridge_cv.best_params_['solver']\n",
    "print(\"Optimal alpha: \", ridge_solver)\n",
    "\n",
    "\n",
    "# Create Ridge linear regression object\n",
    "lin_reg_ridge = Ridge(alpha=ridge_alpha, solver=ridge_solver)\n",
    "\n",
    "# Train the model\n",
    "lin_reg_ridge.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_ridge = lin_reg_ridge.predict(X_train_poly)\n",
    "\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_predicted_ridge))\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % r2_score(y_train, y_train_predicted_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------- Test Model Evaluation -----------------------------\n",
      "\n",
      "Mean squared error: 31.09\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Add polynomial and bias term with the feature vector using the sklearn PolynomialFeatures class\n",
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_test_poly = poly_features.fit_transform(X_test)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Test Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_test_poly_predicted = lin_reg_ridge.predict(X_test_poly)\n",
    "\n",
    "\n",
    "ridge_test_mse = mean_squared_error(y_test, y_test_poly_predicted)\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\" % ridge_test_mse)\n",
    "\n",
    "\n",
    "\n",
    "ridge_test_r2_score = r2_score(y_test, y_test_poly_predicted)\n",
    "print('Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f' \n",
    "      % ridge_test_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (negative mean squared error): -31.422643\n",
      "Optimal Hyperparameter Values:  {'alpha': 30.303030303030305}\n",
      "\n",
      "\n",
      "Wall time: 1.04 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "\n",
    "#param_grid = {'alpha': np.linspace(10.0, 20.0, num=10)}\n",
    "param_grid = {'alpha': np.linspace(10,40,num=100)}\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "lasso_cv = GridSearchCV(ridge, param_grid, scoring='neg_mean_squared_error', cv=10, verbose=1, n_jobs=-1)\n",
    "lasso_cv.fit(X_train_poly, y_train)\n",
    "\n",
    "params_optimal_lasso = lasso_cv.best_params_\n",
    "\n",
    "print(\"Best Score (negative mean squared error): %f\" % lasso_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_lasso)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha:  30.303030303030305\n",
      "\n",
      "----------------------------- Model Evaluation -----------------------------\n",
      "\n",
      "Mean squared error: 27.87\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "\n",
    "# Optimal model parameters\n",
    "lasso_alpha = lasso_cv.best_params_['alpha']\n",
    "print(\"Optimal alpha: \", lasso_alpha)\n",
    "\n",
    "\n",
    "# Create Lasso linear regression object\n",
    "lin_reg_lasso = Ridge(alpha=lasso_alpha)\n",
    "\n",
    "# Train the model\n",
    "lin_reg_lasso.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_lasso = lin_reg_lasso.predict(X_train_poly)\n",
    "\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_predicted_lasso))\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % r2_score(y_train, y_train_predicted_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------- Test Model Evaluation -----------------------------\n",
      "\n",
      "Mean squared error: 30.95\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Add polynomial and bias term with the feature vector using the sklearn PolynomialFeatures class\n",
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_test_poly = poly_features.fit_transform(X_test)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Test Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_test_poly_predicted = lin_reg_lasso.predict(X_test_poly)\n",
    "\n",
    "lasso_test_mse = mean_squared_error(y_test, y_test_poly_predicted)\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\" % lasso_test_mse)\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "\n",
    "lasso_test_r2_score = r2_score(y_test, y_test_poly_predicted)\n",
    "print('Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f' \n",
    "      % lasso_test_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1152 candidates, totalling 11520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2696 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 8572 tasks      | elapsed:   13.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (negative mean squared error): -36.547884\n",
      "Optimal Hyperparameter Values:  {'alpha': 0.001, 'eta0': 0.01, 'l1_ratio': 0.5, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'max_iter': 400}\n",
      "\n",
      "\n",
      "Wall time: 19.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 11520 out of 11520 | elapsed:   19.1s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "param_grid = {'alpha': [0.1, 0.01, 0.001], 'learning_rate': [\"constant\", \"optimal\", \"invscaling\"], \n",
    "              'l1_ratio': [1, 0.5, 0.2, 0], 'max_iter':[100, 400, 1000, 10000],'eta0': [0.01, 0.001],\n",
    "              'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']}\n",
    "\n",
    "\n",
    "\n",
    "sgd = SGDRegressor()\n",
    "\n",
    "sgd_cv = GridSearchCV(sgd, param_grid, scoring='neg_mean_squared_error', cv=10, verbose=2, n_jobs=-1)\n",
    "sgd_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "params_optimal_sgd = sgd_cv.best_params_\n",
    "\n",
    "print(\"Best Score (negative mean squared error): %f\" % sgd_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_sgd)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------- Model Evaluation -----------------------------\n",
      "Mean squared error: 36.29\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.69\n"
     ]
    }
   ],
   "source": [
    "# SGD Regression\n",
    "\n",
    "# Create SGDRegressor linear regression object using the optimal hyperparameter values\n",
    "lin_reg_sgd = SGDRegressor(**params_optimal_sgd)\n",
    "\n",
    "# Train the model\n",
    "lin_reg_sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_sgd = lin_reg_sgd.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_predicted_sgd))\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % r2_score(y_train, y_train_predicted_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-34.5274389  -44.65013497 -52.3007541  -30.0873304  -33.73740282\n",
      " -40.6077716  -40.7134409  -26.54409395 -32.77500768 -36.15402762]\n",
      "Negative Mean Squared Error: -37.21 (+/- 14.30)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scoring Parameter for Regression:\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "scores = cross_val_score(lin_reg_sgd, X_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "print(scores)\n",
    "\n",
    "print(\"Negative Mean Squared Error: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 35.47\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.63\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted = lin_reg_sgd.predict(X_test)\n",
    "\n",
    "\n",
    "test_mse_linear = mean_squared_error(y_test, y_test_predicted)\n",
    "\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % test_mse_linear)\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "test_r2_linear = r2_score(y_test, y_test_predicted)\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % test_r2_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Original Features:  10\n",
      "No. of Augmented Features:  65\n"
     ]
    }
   ],
   "source": [
    "# Variable that speficies the degree of the polynomial to be added to the feature vector\n",
    "poly_degree = 2\n",
    "\n",
    "\n",
    "# Add polynomial terms with the feature vector using the sklearn PolynomialFeatures class\n",
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "\n",
    "\n",
    "print(\"No. of Original Features: \", X_train.shape[1])\n",
    "print(\"No. of Augmented Features: \", X_train_poly.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 384 candidates, totalling 3840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1629 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2272 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3453 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3825 out of 3840 | elapsed:  1.6min remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (negative mean squared error): -31.909812\n",
      "Optimal Hyperparameter Values:  {'alpha': 0.01, 'eta0': 0.001, 'l1_ratio': 0.5, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 1000}\n",
      "\n",
      "\n",
      "Wall time: 1min 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3840 out of 3840 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "# param_grid = {'alpha': [0.1, 0.01], 'learning_rate': [\"invscaling\"], \n",
    "#               'l1_ratio': [1, 0.5, 0.2, 0], 'max_iter':[100, 400, 1000, 5000],'eta0': [0.01, 0.001, 0.0001]}\n",
    "\n",
    "\n",
    "param_grid = {'alpha': [0.1, 0.01], 'learning_rate': [\"invscaling\"], \n",
    "              'l1_ratio': [1, 0.5, 0.2, 0], 'max_iter':[100, 400, 1000, 10000],'eta0': [0.01, 0.001, 0.0001],\n",
    "              'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']}\n",
    "\n",
    "\n",
    "\n",
    "sgd = SGDRegressor()\n",
    "\n",
    "sgd_cv = GridSearchCV(sgd, param_grid, scoring='neg_mean_squared_error', cv=10, verbose=2, n_jobs=-1)\n",
    "sgd_cv.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "params_optimal_sgd = sgd_cv.best_params_\n",
    "\n",
    "print(\"Best Score (negative mean squared error): %f\" % sgd_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_sgd)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Iterations: \n",
      " 94\n",
      "\n",
      "----------------------------- Model Evaluation -----------------------------\n",
      "Mean squared error: 28.22\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.76\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SGD Regression\n",
    "\n",
    "# Create SGDRegressor linear regression object using the optimal hyperparameter values\n",
    "lin_reg_sgd = SGDRegressor(**params_optimal_sgd)\n",
    "\n",
    "# Train the model\n",
    "lin_reg_sgd.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "# # The intercept\n",
    "# print(\"Intercept: \\n\", lin_reg_sgd.intercept_)\n",
    "\n",
    "# # The coefficients\n",
    "# print(\"Coefficients: \\n\", lin_reg_sgd.coef_)\n",
    "\n",
    "# The number of iterations\n",
    "print(\"Number of Iterations: \\n\", lin_reg_sgd.n_iter_)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_sgd = lin_reg_sgd.predict(X_train_poly)\n",
    "\n",
    "\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_predicted_sgd))\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % r2_score(y_train, y_train_predicted_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 31.31\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.68\n"
     ]
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_test_poly = poly_features.fit_transform(X_test)\n",
    "\n",
    "# Make prediction using the test data\n",
    "y_test_predicted = lin_reg_sgd.predict(X_test_poly)\n",
    "\n",
    "test_mse_polynomial = mean_squared_error(y_test, y_test_predicted)\n",
    "\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % test_mse_polynomial)\n",
    "\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "\n",
    "test_r2_polynomial = r2_score(y_test, y_test_predicted)\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % test_r2_polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>SGD Linear Regression</th>\n",
       "      <th>SGD Polynomial Regression (degree 2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE (test)</td>\n",
       "      <td>35.472754</td>\n",
       "      <td>31.310358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R2 Score (test)</td>\n",
       "      <td>0.633114</td>\n",
       "      <td>0.676164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metric  SGD Linear Regression  \\\n",
       "0       MSE (test)              35.472754   \n",
       "1  R2 Score (test)               0.633114   \n",
       "\n",
       "   SGD Polynomial Regression (degree 2)  \n",
       "0                             31.310358  \n",
       "1                              0.676164  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[\"MSE (test)\", test_mse_linear, test_mse_polynomial], \n",
    "        [\"R2 Score (test)\", test_r2_linear, test_r2_polynomial]]\n",
    "pd.DataFrame(data, columns=[\"Metric\", \"SGD Linear Regression\", \"SGD Polynomial Regression (degree 2)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM(RBF kernel) and Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
