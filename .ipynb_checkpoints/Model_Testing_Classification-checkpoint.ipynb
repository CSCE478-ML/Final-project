{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet,SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score,accuracy_score,mean_absolute_error\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point</th>\n",
       "      <th>Trees</th>\n",
       "      <th>Shrubs</th>\n",
       "      <th>Peren_FG</th>\n",
       "      <th>bare_groun</th>\n",
       "      <th>Annual_FG</th>\n",
       "      <th>ppt</th>\n",
       "      <th>vpdmin</th>\n",
       "      <th>vpdmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>...</th>\n",
       "      <th>aspect</th>\n",
       "      <th>Runoff</th>\n",
       "      <th>Frosting_R</th>\n",
       "      <th>Flooding_F</th>\n",
       "      <th>BD_depth</th>\n",
       "      <th>AWS_50cm</th>\n",
       "      <th>AWS_25cm</th>\n",
       "      <th>AWS_150cm</th>\n",
       "      <th>AWS_100cm</th>\n",
       "      <th>Min_WTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>1003.760</td>\n",
       "      <td>8.6440</td>\n",
       "      <td>149.085</td>\n",
       "      <td>49.1187</td>\n",
       "      <td>...</td>\n",
       "      <td>180.0860</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4900</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.4300</td>\n",
       "      <td>22.9200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>822.610</td>\n",
       "      <td>8.9776</td>\n",
       "      <td>138.599</td>\n",
       "      <td>46.5965</td>\n",
       "      <td>...</td>\n",
       "      <td>211.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>849.481</td>\n",
       "      <td>9.4117</td>\n",
       "      <td>138.963</td>\n",
       "      <td>47.8117</td>\n",
       "      <td>...</td>\n",
       "      <td>186.5640</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>854.956</td>\n",
       "      <td>8.1519</td>\n",
       "      <td>135.181</td>\n",
       "      <td>45.4194</td>\n",
       "      <td>...</td>\n",
       "      <td>161.3930</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>849.242</td>\n",
       "      <td>9.2913</td>\n",
       "      <td>138.704</td>\n",
       "      <td>47.6300</td>\n",
       "      <td>...</td>\n",
       "      <td>121.3640</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4792</th>\n",
       "      <td>4793</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>789.471</td>\n",
       "      <td>12.5005</td>\n",
       "      <td>176.244</td>\n",
       "      <td>69.1463</td>\n",
       "      <td>...</td>\n",
       "      <td>297.1450</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1439</td>\n",
       "      <td>1.0640</td>\n",
       "      <td>6.4935</td>\n",
       "      <td>4.3117</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>4794</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>778.307</td>\n",
       "      <td>8.1716</td>\n",
       "      <td>180.426</td>\n",
       "      <td>41.2986</td>\n",
       "      <td>...</td>\n",
       "      <td>25.7692</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>4795</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>706.038</td>\n",
       "      <td>9.8153</td>\n",
       "      <td>175.318</td>\n",
       "      <td>46.5239</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0057</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>4796</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>713.786</td>\n",
       "      <td>13.5313</td>\n",
       "      <td>179.063</td>\n",
       "      <td>65.2216</td>\n",
       "      <td>...</td>\n",
       "      <td>68.3994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1172</td>\n",
       "      <td>1.1507</td>\n",
       "      <td>4.5539</td>\n",
       "      <td>3.3355</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>4797</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>710.399</td>\n",
       "      <td>9.0785</td>\n",
       "      <td>175.871</td>\n",
       "      <td>44.7851</td>\n",
       "      <td>...</td>\n",
       "      <td>196.9770</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.4794</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4797 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Point  Trees  Shrubs  Peren_FG  bare_groun  Annual_FG       ppt  \\\n",
       "0         1     19       8        47           7         22  1003.760   \n",
       "1         2      2       1        66          14          8   822.610   \n",
       "2         3      3       1        69           2         14   849.481   \n",
       "3         4     20       4        51          11         21   854.956   \n",
       "4         5     18      11        50           9         20   849.242   \n",
       "...     ...    ...     ...       ...         ...        ...       ...   \n",
       "4792   4793     13       8        57          15         23   789.471   \n",
       "4793   4794     36       7        43           1         12   778.307   \n",
       "4794   4795     36       9        53           2         13   706.038   \n",
       "4795   4796     33       4        43           3         11   713.786   \n",
       "4796   4797     13       7        57          10         13   710.399   \n",
       "\n",
       "       vpdmin   vpdmax     tmin  ...    aspect  Runoff  Frosting_R  \\\n",
       "0      8.6440  149.085  49.1187  ...  180.0860       3           3   \n",
       "1      8.9776  138.599  46.5965  ...  211.4610       1           3   \n",
       "2      9.4117  138.963  47.8117  ...  186.5640       1           3   \n",
       "3      8.1519  135.181  45.4194  ...  161.3930       1           3   \n",
       "4      9.2913  138.704  47.6300  ...  121.3640       1           3   \n",
       "...       ...      ...      ...  ...       ...     ...         ...   \n",
       "4792  12.5005  176.244  69.1463  ...  297.1450       0          -1   \n",
       "4793   8.1716  180.426  41.2986  ...   25.7692       6           2   \n",
       "4794   9.8153  175.318  46.5239  ...   21.0057       6           2   \n",
       "4795  13.5313  179.063  65.2216  ...   68.3994       0           0   \n",
       "4796   9.0785  175.871  44.7851  ...  196.9770      -1          -1   \n",
       "\n",
       "      Flooding_F  BD_depth  AWS_50cm  AWS_25cm  AWS_150cm  AWS_100cm  Min_WTD  \n",
       "0              3       0.0   11.4900    5.7500    33.4300    22.9200    153.0  \n",
       "1              3       0.0   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "2              3       0.0   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "3              3       0.0   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "4              3       0.0   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "...          ...       ...       ...       ...        ...        ...      ...  \n",
       "4792           0       0.0    2.1439    1.0640     6.4935     4.3117      0.0  \n",
       "4793           1      38.0    3.9900    2.5500     3.9900     3.9900      0.0  \n",
       "4794           1      38.0    3.9900    2.5500     3.9900     3.9900      0.0  \n",
       "4795           0       0.0    2.1172    1.1507     4.5539     3.3355      0.0  \n",
       "4796          -1       0.0    0.2470    0.1402     0.4794     0.3636      0.0  \n",
       "\n",
       "[4797 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df.values.ravel() == -1).reshape(df.shape).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point</th>\n",
       "      <th>Trees</th>\n",
       "      <th>Shrubs</th>\n",
       "      <th>Peren_FG</th>\n",
       "      <th>bare_groun</th>\n",
       "      <th>Annual_FG</th>\n",
       "      <th>ppt</th>\n",
       "      <th>vpdmin</th>\n",
       "      <th>vpdmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>...</th>\n",
       "      <th>aspect</th>\n",
       "      <th>Runoff</th>\n",
       "      <th>Frosting_R</th>\n",
       "      <th>Flooding_F</th>\n",
       "      <th>BD_depth</th>\n",
       "      <th>AWS_50cm</th>\n",
       "      <th>AWS_25cm</th>\n",
       "      <th>AWS_150cm</th>\n",
       "      <th>AWS_100cm</th>\n",
       "      <th>Min_WTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>1003.760</td>\n",
       "      <td>8.6440</td>\n",
       "      <td>149.085</td>\n",
       "      <td>49.1187</td>\n",
       "      <td>...</td>\n",
       "      <td>180.0860</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.4900</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.4300</td>\n",
       "      <td>22.9200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>822.610</td>\n",
       "      <td>8.9776</td>\n",
       "      <td>138.599</td>\n",
       "      <td>46.5965</td>\n",
       "      <td>...</td>\n",
       "      <td>211.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>849.481</td>\n",
       "      <td>9.4117</td>\n",
       "      <td>138.963</td>\n",
       "      <td>47.8117</td>\n",
       "      <td>...</td>\n",
       "      <td>186.5640</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>854.956</td>\n",
       "      <td>8.1519</td>\n",
       "      <td>135.181</td>\n",
       "      <td>45.4194</td>\n",
       "      <td>...</td>\n",
       "      <td>161.3930</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>849.242</td>\n",
       "      <td>9.2913</td>\n",
       "      <td>138.704</td>\n",
       "      <td>47.6300</td>\n",
       "      <td>...</td>\n",
       "      <td>121.3640</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>4791</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>828.338</td>\n",
       "      <td>8.7542</td>\n",
       "      <td>180.391</td>\n",
       "      <td>42.9977</td>\n",
       "      <td>...</td>\n",
       "      <td>269.6360</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>5.1000</td>\n",
       "      <td>4.2500</td>\n",
       "      <td>5.1000</td>\n",
       "      <td>5.1000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>4792</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>868.329</td>\n",
       "      <td>8.8903</td>\n",
       "      <td>176.260</td>\n",
       "      <td>40.5698</td>\n",
       "      <td>...</td>\n",
       "      <td>301.8970</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40.1869</td>\n",
       "      <td>4.1027</td>\n",
       "      <td>2.5825</td>\n",
       "      <td>4.4481</td>\n",
       "      <td>4.3668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>4794</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>778.307</td>\n",
       "      <td>8.1716</td>\n",
       "      <td>180.426</td>\n",
       "      <td>41.2986</td>\n",
       "      <td>...</td>\n",
       "      <td>25.7692</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>4795</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>706.038</td>\n",
       "      <td>9.8153</td>\n",
       "      <td>175.318</td>\n",
       "      <td>46.5239</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0057</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>4796</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>713.786</td>\n",
       "      <td>13.5313</td>\n",
       "      <td>179.063</td>\n",
       "      <td>65.2216</td>\n",
       "      <td>...</td>\n",
       "      <td>68.3994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.1172</td>\n",
       "      <td>1.1507</td>\n",
       "      <td>4.5539</td>\n",
       "      <td>3.3355</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4180 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Point  Trees  Shrubs  Peren_FG  bare_groun  Annual_FG       ppt  \\\n",
       "0         1     19       8        47           7         22  1003.760   \n",
       "1         2      2       1        66          14          8   822.610   \n",
       "2         3      3       1        69           2         14   849.481   \n",
       "3         4     20       4        51          11         21   854.956   \n",
       "4         5     18      11        50           9         20   849.242   \n",
       "...     ...    ...     ...       ...         ...        ...       ...   \n",
       "4790   4791     51       7        43           3         10   828.338   \n",
       "4791   4792     17       7        67           1         10   868.329   \n",
       "4793   4794     36       7        43           1         12   778.307   \n",
       "4794   4795     36       9        53           2         13   706.038   \n",
       "4795   4796     33       4        43           3         11   713.786   \n",
       "\n",
       "       vpdmin   vpdmax     tmin  ...    aspect  Runoff  Frosting_R  \\\n",
       "0      8.6440  149.085  49.1187  ...  180.0860       3           3   \n",
       "1      8.9776  138.599  46.5965  ...  211.4610       1           3   \n",
       "2      9.4117  138.963  47.8117  ...  186.5640       1           3   \n",
       "3      8.1519  135.181  45.4194  ...  161.3930       1           3   \n",
       "4      9.2913  138.704  47.6300  ...  121.3640       1           3   \n",
       "...       ...      ...      ...  ...       ...     ...         ...   \n",
       "4790   8.7542  180.391  42.9977  ...  269.6360       5           2   \n",
       "4791   8.8903  176.260  40.5698  ...  301.8970       6           2   \n",
       "4793   8.1716  180.426  41.2986  ...   25.7692       6           2   \n",
       "4794   9.8153  175.318  46.5239  ...   21.0057       6           2   \n",
       "4795  13.5313  179.063  65.2216  ...   68.3994       0           0   \n",
       "\n",
       "      Flooding_F  BD_depth  AWS_50cm  AWS_25cm  AWS_150cm  AWS_100cm  Min_WTD  \n",
       "0              3    0.0000   11.4900    5.7500    33.4300    22.9200    153.0  \n",
       "1              3    0.0000   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "2              3    0.0000   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "3              3    0.0000   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "4              3    0.0000   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "...          ...       ...       ...       ...        ...        ...      ...  \n",
       "4790           1   38.0000    5.1000    4.2500     5.1000     5.1000      0.0  \n",
       "4791           1   40.1869    4.1027    2.5825     4.4481     4.3668      0.0  \n",
       "4793           1   38.0000    3.9900    2.5500     3.9900     3.9900      0.0  \n",
       "4794           1   38.0000    3.9900    2.5500     3.9900     3.9900      0.0  \n",
       "4795           0    0.0000    2.1172    1.1507     4.5539     3.3355      0.0  \n",
       "\n",
       "[4180 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(frac=1) #Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Trees']= (df['Trees'] > 40).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Trees']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_mse = ['Shrubs', 'Peren_FG', 'bare_groun', 'Annual_FG', 'vpdmax', 'tmean',\n",
    "       'slope', 'Runoff', 'Flooding_F', 'BD_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = df[best_feature_mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(best_df)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3344, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC (Current optimal with current data processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LinSVC = LinearSVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Score: 0.990131\n",
      "\n",
      "Optimal Hyperparameter Values: \n",
      "C: 1\n",
      "loss: 'hinge'\n",
      "max_iter: 35\n",
      "penalty: 'l2'\n",
      "tol: 0.1\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "param_grid = {\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C' : [ 1 , 35, 50, 100, 500, 1000],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'tol' : [0.1 , 0.01, 0.001, 0.0001],\n",
    "    'max_iter' : [10, 35, 50, 100, 500, 1000, 5000, 10000],\n",
    "}\n",
    "\n",
    "LinSVC_cv = GridSearchCV(LinSVC, param_grid, scoring='accuracy', cv=5)\n",
    "\n",
    "LinSVC_cv = LinSVC_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Score: %f\" % LinSVC_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, LinSVC_cv.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9895334928229665\n",
      "Test Accuracy:  0.9916267942583732\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[813   4]\n",
      " [  3  16]]\n",
      "\n",
      "Test Precision = 0.800000\n",
      "Test Recall = 0.842105\n",
      "Test F1 Score = 0.820513\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       817\n",
      "           1       0.80      0.84      0.82        19\n",
      "\n",
      "    accuracy                           0.99       836\n",
      "   macro avg       0.90      0.92      0.91       836\n",
      "weighted avg       0.99      0.99      0.99       836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LinSVC= LinearSVC(random_state=42, C=LinSVC_cv.best_params_['C'], loss=LinSVC_cv.best_params_['loss'], max_iter=LinSVC_cv.best_params_['max_iter'], penalty= LinSVC_cv.best_params_['penalty'], tol=LinSVC_cv.best_params_['tol']).fit(X_train, y_train)\n",
    "LinSVC.fit(X_train, y_train)\n",
    "\n",
    "y_train_predicted = LinSVC.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"Training Accuracy: \", LinSVC.score(X_train, y_train))\n",
    "y_test_predicted = LinSVC.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Test Accuracy: \", LinSVC.score(X_test, y_test))\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted) \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted)\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted)\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Prediction of &lt;=40% Trees</th>\n",
       "      <th>Prediction of &gt;40% Trees</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Macro Avg</th>\n",
       "      <th>Weigted Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision (test)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.898162</td>\n",
       "      <td>0.991862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall (test)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.918605</td>\n",
       "      <td>0.991627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1-score (test)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.991627</td>\n",
       "      <td>0.908113</td>\n",
       "      <td>0.991732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Metric  Prediction of <=40% Trees  Prediction of >40% Trees  \\\n",
       "0  Precision (test)                        1.0                  0.800000   \n",
       "1     Recall (test)                        1.0                  0.842105   \n",
       "2   f1-score (test)                        1.0                  0.820513   \n",
       "\n",
       "  Test Accuracy  Macro Avg  Weigted Avg  \n",
       "0           N/A   0.898162     0.991862  \n",
       "1           N/A   0.918605     0.991627  \n",
       "2      0.991627   0.908113     0.991732  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[\"Precision (test)\", 1.00, precision_test, \"N/A\", 0.8981617647058824, 0.9918616310160429], \n",
    "        [\"Recall (test)\", 1.00, recall_test, \"N/A\", 0.9186046511627907, 0.9916267942583732],[\"f1-score (test)\", 1.00, f1_test, LinSVC.score(X_test, y_test), 0.9081131157065021, 0.9917315793004708]]\n",
    "pd.DataFrame(data, columns=[\"Metric\", \"Prediction of <=40% Trees\", \"Prediction of >40% Trees\", \"Test Accuracy\", \"Macro Avg\", \"Weigted Avg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_support_vectors(svm_clf, scaler, X, y):\n",
    "    w_unscaled = svm_clf.coef_[0] / scaler.scale_\n",
    "\n",
    "\n",
    "    b_scaled = svm_clf.intercept_\n",
    "    #print(\"b_scaled: \", b_scaled)\n",
    "\n",
    "    # Following term is subtracted from the b_scaled\n",
    "    b_subtract = [(svm_clf.coef_[0]).T.dot(-scaler.mean_ / scaler.scale_)]\n",
    "    #print(\"b_subtract: \", b_subtract)\n",
    "\n",
    "    b_unscaled = np.array(b_scaled + b_subtract)\n",
    "    #print(\"b_unscaled: \", b_unscaled)\n",
    "\n",
    "    # Update the weight and intercept of the model with the unscaled weight parameters\n",
    "    svm_clf.intercept_ = np.array([b_unscaled])\n",
    "\n",
    "    svm_clf.coef_ = np.array([w_unscaled])\n",
    "    \n",
    "    \n",
    "    # Now compute the support vectors.\n",
    "\n",
    "    # The original class labels are 0 and 1.\n",
    "    # We need to transform them to -1 and 1.\n",
    "    t = y * 2 - 1\n",
    "\n",
    "\n",
    "    # Note that the data points are classified according to the following rule:\n",
    "    #  (t * (X.dot(w) + b) >= 1)\n",
    "    # Thus the support vectors will satisfy: (t * (X.dot(w) + b) < 1)\n",
    "\n",
    "    support_vectors_idx = (t * (X.dot(w_unscaled) + b_unscaled) < 1).ravel()\n",
    "\n",
    "    svm_clf.support_vectors_ = X[support_vectors_idx]\n",
    "\n",
    "\n",
    "    return svm_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decision_boundary_support_vectors(svm_clf, X):\n",
    "    \n",
    "    xmin, xmax = X.min() - 1, X.max() + 1\n",
    "    \n",
    "    w = svm_clf.coef_[0]\n",
    "    b = svm_clf.intercept_[0]\n",
    "\n",
    "    # At the decision boundary, w1*x1 + w2*x2 + b = 0\n",
    "    # => x2 = -(b + w1* x1)/w1\n",
    "    x1 = np.linspace(xmin, xmax, 100)\n",
    "    \n",
    "    decision_boundary = -(b + w[0]*x1)/w[1]\n",
    "\n",
    "    shifting_factor_for_margin = 1/w[1]\n",
    "    upper_margin = decision_boundary + shifting_factor_for_margin\n",
    "    lower_margin = decision_boundary - shifting_factor_for_margin\n",
    "\n",
    "    svs = svm_clf.support_vectors_\n",
    "    plt.scatter(svs[:, 0], svs[:, 1], s=200, facecolors='g', label=\"Support Vectors\")\n",
    "    plt.plot(x1, decision_boundary, \"k-\", linewidth=2)\n",
    "    plt.plot(x1, upper_margin, \"k--\", linewidth=2)\n",
    "    plt.plot(x1, lower_margin, \"k--\", linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_boundary_svc_class_colored(clf, X, plotDistanceFromHyperplane=False, colorBar=False):\n",
    "    \n",
    "    # Get the min and max value of feature x1\n",
    "    x1min, x1max = X[:,0].min() - 1, X[:, 0].max() + 1\n",
    "    \n",
    "    # Get the min and max value of feature x2\n",
    "    x2min, x2max = X[:,1].min() - 1, X[:, 1].max() + 1\n",
    "    \n",
    "    # Create the mesh grid\n",
    "    x1s = np.linspace(x1min, x1max, 100)\n",
    "    x2s = np.linspace(x2min, x2max, 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    \n",
    "    \n",
    "    # Create pairs of new points from the grid\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    \n",
    "    \n",
    "    # Compute the class predictions for all new points\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    \n",
    "    \n",
    "    # Generate the contourf plot for the predictions\n",
    "    plt.contourf(x1, x2, y_pred, cmap=plt.cm.bwr, alpha=0.2)\n",
    "    \n",
    "    \n",
    "    if(plotDistanceFromHyperplane == True):\n",
    "    \n",
    "        # Compute the signed distance of a sample to the hyperplane for all new points\n",
    "        y_decision = clf.decision_function(X_new).reshape(x1.shape)\n",
    "\n",
    "        # Generate the contour plot for the distance of all points from the hyperplane and the two margins\n",
    "        plt.contour(x1, x2, y_decision, levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'], colors='black')\n",
    "        \n",
    "        \n",
    "        #plt.pcolormesh(x1, x2, -y_decision, cmap=plt.cm.RdBu)\n",
    "        \n",
    "        # Generate the contourf plot for the distance of all points from the hyperplane\n",
    "        plt.contourf(x1, x2, y_decision, cmap=plt.cm.bwr, alpha=0.2)\n",
    "    \n",
    "    \n",
    "    if(colorBar==True):\n",
    "        plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40933868, -0.12832676,  1.16123879, ...,  1.90521266,\n",
       "        -0.47572371, -0.13130595],\n",
       "       [-1.50294336,  1.97987605, -1.57628854, ..., -0.80413505,\n",
       "        -0.47572371, -0.13130595],\n",
       "       [-0.04480378,  0.92577464, -0.8919067 , ...,  1.22787574,\n",
       "        -0.47572371, -0.13130595],\n",
       "       ...,\n",
       "       [ 0.68426601,  0.92577464,  0.99014333, ..., -0.12679812,\n",
       "        -0.47572371, -0.13130595],\n",
       "       [ 1.4133358 , -1.39324844,  0.3057615 , ..., -0.12679812,\n",
       "        -0.47572371, -0.13130595],\n",
       "       [ 1.4133358 , -0.86619774, -0.20752487, ...,  0.55053881,\n",
       "        -0.47572371, -0.13130595]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = compute_support_vectors(LinSVC, scaler, X_train, y_train)\n",
    "svm_clf.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 2 features per sample; expecting 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-466a3731e0e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ro\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Class 1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdecision_boundary_svc_class_colored\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplotDistanceFromHyperplane\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolorBar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# We can plot the support vectors on the margin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-6778ed09c5f4>\u001b[0m in \u001b[0;36mdecision_boundary_svc_class_colored\u001b[1;34m(clf, X, plotDistanceFromHyperplane, colorBar)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Compute the class predictions for all new points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[0;32m    287\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2 features per sample; expecting 10"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(121)\n",
    "\n",
    "\n",
    "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bo\", label=\"Class 0\")\n",
    "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"ro\", label=\"Class 1\")\n",
    "\n",
    "#decision_boundary_svc_class_colored(svm_clf, X_train, plotDistanceFromHyperplane=True, colorBar=False)\n",
    "\n",
    "# We can plot the support vectors on the margin\n",
    "decision_boundary_support_vectors(svm_clf, X_train)\n",
    "\n",
    "plt.xlabel(\"x1\", fontsize=14)\n",
    "plt.ylabel(\"x2\", fontsize=14)\n",
    "plt.legend(loc=\"best\", fontsize=14)\n",
    "plt.title(\"LinearSVC Classifier: $C = {}$\".format(svm_clf.C), fontsize=16)\n",
    "plt.axis([0.4, 1, 4, 8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
