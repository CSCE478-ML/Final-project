{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet,SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score,accuracy_score,mean_absolute_error\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point</th>\n",
       "      <th>Trees</th>\n",
       "      <th>Shrubs</th>\n",
       "      <th>Peren_FG</th>\n",
       "      <th>bare_groun</th>\n",
       "      <th>Annual_FG</th>\n",
       "      <th>ppt</th>\n",
       "      <th>vpdmin</th>\n",
       "      <th>vpdmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>...</th>\n",
       "      <th>aspect</th>\n",
       "      <th>Runoff</th>\n",
       "      <th>Frosting_R</th>\n",
       "      <th>Flooding_F</th>\n",
       "      <th>BD_depth</th>\n",
       "      <th>AWS_50cm</th>\n",
       "      <th>AWS_25cm</th>\n",
       "      <th>AWS_150cm</th>\n",
       "      <th>AWS_100cm</th>\n",
       "      <th>Min_WTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>1003.760</td>\n",
       "      <td>8.6440</td>\n",
       "      <td>149.085</td>\n",
       "      <td>49.1187</td>\n",
       "      <td>...</td>\n",
       "      <td>180.0860</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4900</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.4300</td>\n",
       "      <td>22.9200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>822.610</td>\n",
       "      <td>8.9776</td>\n",
       "      <td>138.599</td>\n",
       "      <td>46.5965</td>\n",
       "      <td>...</td>\n",
       "      <td>211.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>849.481</td>\n",
       "      <td>9.4117</td>\n",
       "      <td>138.963</td>\n",
       "      <td>47.8117</td>\n",
       "      <td>...</td>\n",
       "      <td>186.5640</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>854.956</td>\n",
       "      <td>8.1519</td>\n",
       "      <td>135.181</td>\n",
       "      <td>45.4194</td>\n",
       "      <td>...</td>\n",
       "      <td>161.3930</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>849.242</td>\n",
       "      <td>9.2913</td>\n",
       "      <td>138.704</td>\n",
       "      <td>47.6300</td>\n",
       "      <td>...</td>\n",
       "      <td>121.3640</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4792</th>\n",
       "      <td>4793</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>789.471</td>\n",
       "      <td>12.5005</td>\n",
       "      <td>176.244</td>\n",
       "      <td>69.1463</td>\n",
       "      <td>...</td>\n",
       "      <td>297.1450</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1439</td>\n",
       "      <td>1.0640</td>\n",
       "      <td>6.4935</td>\n",
       "      <td>4.3117</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>4794</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>778.307</td>\n",
       "      <td>8.1716</td>\n",
       "      <td>180.426</td>\n",
       "      <td>41.2986</td>\n",
       "      <td>...</td>\n",
       "      <td>25.7692</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>4795</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>706.038</td>\n",
       "      <td>9.8153</td>\n",
       "      <td>175.318</td>\n",
       "      <td>46.5239</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0057</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>4796</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>713.786</td>\n",
       "      <td>13.5313</td>\n",
       "      <td>179.063</td>\n",
       "      <td>65.2216</td>\n",
       "      <td>...</td>\n",
       "      <td>68.3994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1172</td>\n",
       "      <td>1.1507</td>\n",
       "      <td>4.5539</td>\n",
       "      <td>3.3355</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>4797</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>710.399</td>\n",
       "      <td>9.0785</td>\n",
       "      <td>175.871</td>\n",
       "      <td>44.7851</td>\n",
       "      <td>...</td>\n",
       "      <td>196.9770</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.4794</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4797 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Point  Trees  Shrubs  Peren_FG  bare_groun  Annual_FG       ppt  \\\n",
       "0         1     19       8        47           7         22  1003.760   \n",
       "1         2      2       1        66          14          8   822.610   \n",
       "2         3      3       1        69           2         14   849.481   \n",
       "3         4     20       4        51          11         21   854.956   \n",
       "4         5     18      11        50           9         20   849.242   \n",
       "...     ...    ...     ...       ...         ...        ...       ...   \n",
       "4792   4793     13       8        57          15         23   789.471   \n",
       "4793   4794     36       7        43           1         12   778.307   \n",
       "4794   4795     36       9        53           2         13   706.038   \n",
       "4795   4796     33       4        43           3         11   713.786   \n",
       "4796   4797     13       7        57          10         13   710.399   \n",
       "\n",
       "       vpdmin   vpdmax     tmin  ...    aspect  Runoff  Frosting_R  \\\n",
       "0      8.6440  149.085  49.1187  ...  180.0860       3           3   \n",
       "1      8.9776  138.599  46.5965  ...  211.4610       1           3   \n",
       "2      9.4117  138.963  47.8117  ...  186.5640       1           3   \n",
       "3      8.1519  135.181  45.4194  ...  161.3930       1           3   \n",
       "4      9.2913  138.704  47.6300  ...  121.3640       1           3   \n",
       "...       ...      ...      ...  ...       ...     ...         ...   \n",
       "4792  12.5005  176.244  69.1463  ...  297.1450       0          -1   \n",
       "4793   8.1716  180.426  41.2986  ...   25.7692       6           2   \n",
       "4794   9.8153  175.318  46.5239  ...   21.0057       6           2   \n",
       "4795  13.5313  179.063  65.2216  ...   68.3994       0           0   \n",
       "4796   9.0785  175.871  44.7851  ...  196.9770      -1          -1   \n",
       "\n",
       "      Flooding_F  BD_depth  AWS_50cm  AWS_25cm  AWS_150cm  AWS_100cm  Min_WTD  \n",
       "0              3       0.0   11.4900    5.7500    33.4300    22.9200    153.0  \n",
       "1              3       0.0   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "2              3       0.0   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "3              3       0.0   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "4              3       0.0   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "...          ...       ...       ...       ...        ...        ...      ...  \n",
       "4792           0       0.0    2.1439    1.0640     6.4935     4.3117      0.0  \n",
       "4793           1      38.0    3.9900    2.5500     3.9900     3.9900      0.0  \n",
       "4794           1      38.0    3.9900    2.5500     3.9900     3.9900      0.0  \n",
       "4795           0       0.0    2.1172    1.1507     4.5539     3.3355      0.0  \n",
       "4796          -1       0.0    0.2470    0.1402     0.4794     0.3636      0.0  \n",
       "\n",
       "[4797 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df.values.ravel() == -1).reshape(df.shape).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point</th>\n",
       "      <th>Trees</th>\n",
       "      <th>Shrubs</th>\n",
       "      <th>Peren_FG</th>\n",
       "      <th>bare_groun</th>\n",
       "      <th>Annual_FG</th>\n",
       "      <th>ppt</th>\n",
       "      <th>vpdmin</th>\n",
       "      <th>vpdmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>...</th>\n",
       "      <th>aspect</th>\n",
       "      <th>Runoff</th>\n",
       "      <th>Frosting_R</th>\n",
       "      <th>Flooding_F</th>\n",
       "      <th>BD_depth</th>\n",
       "      <th>AWS_50cm</th>\n",
       "      <th>AWS_25cm</th>\n",
       "      <th>AWS_150cm</th>\n",
       "      <th>AWS_100cm</th>\n",
       "      <th>Min_WTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>1003.760</td>\n",
       "      <td>8.6440</td>\n",
       "      <td>149.085</td>\n",
       "      <td>49.1187</td>\n",
       "      <td>...</td>\n",
       "      <td>180.0860</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.4900</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.4300</td>\n",
       "      <td>22.9200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>822.610</td>\n",
       "      <td>8.9776</td>\n",
       "      <td>138.599</td>\n",
       "      <td>46.5965</td>\n",
       "      <td>...</td>\n",
       "      <td>211.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>849.481</td>\n",
       "      <td>9.4117</td>\n",
       "      <td>138.963</td>\n",
       "      <td>47.8117</td>\n",
       "      <td>...</td>\n",
       "      <td>186.5640</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>854.956</td>\n",
       "      <td>8.1519</td>\n",
       "      <td>135.181</td>\n",
       "      <td>45.4194</td>\n",
       "      <td>...</td>\n",
       "      <td>161.3930</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>849.242</td>\n",
       "      <td>9.2913</td>\n",
       "      <td>138.704</td>\n",
       "      <td>47.6300</td>\n",
       "      <td>...</td>\n",
       "      <td>121.3640</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>4791</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>828.338</td>\n",
       "      <td>8.7542</td>\n",
       "      <td>180.391</td>\n",
       "      <td>42.9977</td>\n",
       "      <td>...</td>\n",
       "      <td>269.6360</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>5.1000</td>\n",
       "      <td>4.2500</td>\n",
       "      <td>5.1000</td>\n",
       "      <td>5.1000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>4792</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>868.329</td>\n",
       "      <td>8.8903</td>\n",
       "      <td>176.260</td>\n",
       "      <td>40.5698</td>\n",
       "      <td>...</td>\n",
       "      <td>301.8970</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40.1869</td>\n",
       "      <td>4.1027</td>\n",
       "      <td>2.5825</td>\n",
       "      <td>4.4481</td>\n",
       "      <td>4.3668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>4794</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>778.307</td>\n",
       "      <td>8.1716</td>\n",
       "      <td>180.426</td>\n",
       "      <td>41.2986</td>\n",
       "      <td>...</td>\n",
       "      <td>25.7692</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>4795</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>706.038</td>\n",
       "      <td>9.8153</td>\n",
       "      <td>175.318</td>\n",
       "      <td>46.5239</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0057</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>4796</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>713.786</td>\n",
       "      <td>13.5313</td>\n",
       "      <td>179.063</td>\n",
       "      <td>65.2216</td>\n",
       "      <td>...</td>\n",
       "      <td>68.3994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.1172</td>\n",
       "      <td>1.1507</td>\n",
       "      <td>4.5539</td>\n",
       "      <td>3.3355</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4180 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Point  Trees  Shrubs  Peren_FG  bare_groun  Annual_FG       ppt  \\\n",
       "0         1     19       8        47           7         22  1003.760   \n",
       "1         2      2       1        66          14          8   822.610   \n",
       "2         3      3       1        69           2         14   849.481   \n",
       "3         4     20       4        51          11         21   854.956   \n",
       "4         5     18      11        50           9         20   849.242   \n",
       "...     ...    ...     ...       ...         ...        ...       ...   \n",
       "4790   4791     51       7        43           3         10   828.338   \n",
       "4791   4792     17       7        67           1         10   868.329   \n",
       "4793   4794     36       7        43           1         12   778.307   \n",
       "4794   4795     36       9        53           2         13   706.038   \n",
       "4795   4796     33       4        43           3         11   713.786   \n",
       "\n",
       "       vpdmin   vpdmax     tmin  ...    aspect  Runoff  Frosting_R  \\\n",
       "0      8.6440  149.085  49.1187  ...  180.0860       3           3   \n",
       "1      8.9776  138.599  46.5965  ...  211.4610       1           3   \n",
       "2      9.4117  138.963  47.8117  ...  186.5640       1           3   \n",
       "3      8.1519  135.181  45.4194  ...  161.3930       1           3   \n",
       "4      9.2913  138.704  47.6300  ...  121.3640       1           3   \n",
       "...       ...      ...      ...  ...       ...     ...         ...   \n",
       "4790   8.7542  180.391  42.9977  ...  269.6360       5           2   \n",
       "4791   8.8903  176.260  40.5698  ...  301.8970       6           2   \n",
       "4793   8.1716  180.426  41.2986  ...   25.7692       6           2   \n",
       "4794   9.8153  175.318  46.5239  ...   21.0057       6           2   \n",
       "4795  13.5313  179.063  65.2216  ...   68.3994       0           0   \n",
       "\n",
       "      Flooding_F  BD_depth  AWS_50cm  AWS_25cm  AWS_150cm  AWS_100cm  Min_WTD  \n",
       "0              3    0.0000   11.4900    5.7500    33.4300    22.9200    153.0  \n",
       "1              3    0.0000   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "2              3    0.0000   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "3              3    0.0000   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "4              3    0.0000   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "...          ...       ...       ...       ...        ...        ...      ...  \n",
       "4790           1   38.0000    5.1000    4.2500     5.1000     5.1000      0.0  \n",
       "4791           1   40.1869    4.1027    2.5825     4.4481     4.3668      0.0  \n",
       "4793           1   38.0000    3.9900    2.5500     3.9900     3.9900      0.0  \n",
       "4794           1   38.0000    3.9900    2.5500     3.9900     3.9900      0.0  \n",
       "4795           0    0.0000    2.1172    1.1507     4.5539     3.3355      0.0  \n",
       "\n",
       "[4180 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(frac=1) #Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Trees']= (df['Trees'] > 40).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Trees']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_mse = ['Shrubs', 'Peren_FG', 'bare_groun', 'Annual_FG', 'vpdmax', 'tmean',\n",
    "       'slope', 'Runoff', 'Flooding_F', 'BD_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = df[best_feature_mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(best_df)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3344, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC (Current optimal with current data processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LinSVC = LinearSVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Score: 0.990131\n",
      "\n",
      "Optimal Hyperparameter Values: \n",
      "C: 1\n",
      "loss: 'hinge'\n",
      "max_iter: 35\n",
      "penalty: 'l2'\n",
      "tol: 0.1\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "param_grid = {\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C' : [ 1 , 35, 50, 100, 500, 1000],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'tol' : [0.1 , 0.01, 0.001, 0.0001],\n",
    "    'max_iter' : [10, 35, 50, 100, 500, 1000, 5000, 10000],\n",
    "}\n",
    "\n",
    "LinSVC_cv = GridSearchCV(LinSVC, param_grid, scoring='accuracy', cv=5)\n",
    "\n",
    "LinSVC_cv = LinSVC_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Score: %f\" % LinSVC_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, LinSVC_cv.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9895334928229665\n",
      "Test Accuracy:  0.9916267942583732\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[813   4]\n",
      " [  3  16]]\n",
      "\n",
      "Test Precision = 0.800000\n",
      "Test Recall = 0.842105\n",
      "Test F1 Score = 0.820513\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       817\n",
      "           1       0.80      0.84      0.82        19\n",
      "\n",
      "    accuracy                           0.99       836\n",
      "   macro avg       0.90      0.92      0.91       836\n",
      "weighted avg       0.99      0.99      0.99       836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LinSVC= LinearSVC(random_state=42, C=LinSVC_cv.best_params_['C'], loss=LinSVC_cv.best_params_['loss'], max_iter=LinSVC_cv.best_params_['max_iter'], penalty= LinSVC_cv.best_params_['penalty'], tol=LinSVC_cv.best_params_['tol']).fit(X_train, y_train)\n",
    "LinSVC.fit(X_train, y_train)\n",
    "\n",
    "y_train_predicted = LinSVC.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"Training Accuracy: \", LinSVC.score(X_train, y_train))\n",
    "y_test_predicted = LinSVC.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Test Accuracy: \", LinSVC.score(X_test, y_test))\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted) \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted)\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted)\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Prediction of &lt;=40% Trees</th>\n",
       "      <th>Prediction of &gt;40% Trees</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Macro Avg</th>\n",
       "      <th>Weigted Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision (test)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.898162</td>\n",
       "      <td>0.991862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall (test)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.918605</td>\n",
       "      <td>0.991627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1-score (test)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.991627</td>\n",
       "      <td>0.908113</td>\n",
       "      <td>0.991732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Metric  Prediction of <=40% Trees  Prediction of >40% Trees  \\\n",
       "0  Precision (test)                        1.0                  0.800000   \n",
       "1     Recall (test)                        1.0                  0.842105   \n",
       "2   f1-score (test)                        1.0                  0.820513   \n",
       "\n",
       "  Test Accuracy  Macro Avg  Weigted Avg  \n",
       "0           N/A   0.898162     0.991862  \n",
       "1           N/A   0.918605     0.991627  \n",
       "2      0.991627   0.908113     0.991732  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[\"Precision (test)\", 1.00, precision_test, \"N/A\", 0.8981617647058824, 0.9918616310160429], \n",
    "        [\"Recall (test)\", 1.00, recall_test, \"N/A\", 0.9186046511627907, 0.9916267942583732],[\"f1-score (test)\", 1.00, f1_test, LinSVC.score(X_test, y_test), 0.9081131157065021, 0.9917315793004708]]\n",
    "pd.DataFrame(data, columns=[\"Metric\", \"Prediction of <=40% Trees\", \"Prediction of >40% Trees\", \"Test Accuracy\", \"Macro Avg\", \"Weigted Avg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_support_vectors(svm_clf, scaler, X, y):\n",
    "    w_unscaled = svm_clf.coef_[0] / scaler.scale_\n",
    "\n",
    "\n",
    "    b_scaled = svm_clf.intercept_\n",
    "    #print(\"b_scaled: \", b_scaled)\n",
    "\n",
    "    # Following term is subtracted from the b_scaled\n",
    "    b_subtract = [(svm_clf.coef_[0]).T.dot(-scaler.mean_ / scaler.scale_)]\n",
    "    #print(\"b_subtract: \", b_subtract)\n",
    "\n",
    "    b_unscaled = np.array(b_scaled + b_subtract)\n",
    "    #print(\"b_unscaled: \", b_unscaled)\n",
    "\n",
    "    # Update the weight and intercept of the model with the unscaled weight parameters\n",
    "    svm_clf.intercept_ = np.array([b_unscaled])\n",
    "\n",
    "    svm_clf.coef_ = np.array([w_unscaled])\n",
    "    \n",
    "    \n",
    "    # Now compute the support vectors.\n",
    "\n",
    "    # The original class labels are 0 and 1.\n",
    "    # We need to transform them to -1 and 1.\n",
    "    t = y * 2 - 1\n",
    "\n",
    "\n",
    "    # Note that the data points are classified according to the following rule:\n",
    "    #  (t * (X.dot(w) + b) >= 1)\n",
    "    # Thus the support vectors will satisfy: (t * (X.dot(w) + b) < 1)\n",
    "\n",
    "    support_vectors_idx = (t * (X.dot(w_unscaled) + b_unscaled) < 1).ravel()\n",
    "\n",
    "    svm_clf.support_vectors_ = X[support_vectors_idx]\n",
    "\n",
    "\n",
    "    return svm_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decision_boundary_support_vectors(svm_clf, X):\n",
    "    \n",
    "    xmin, xmax = X.min() - 1, X.max() + 1\n",
    "    \n",
    "    w = svm_clf.coef_[0]\n",
    "    b = svm_clf.intercept_[0]\n",
    "\n",
    "    # At the decision boundary, w1*x1 + w2*x2 + b = 0\n",
    "    # => x2 = -(b + w1* x1)/w1\n",
    "    x1 = np.linspace(xmin, xmax, 100)\n",
    "    \n",
    "    decision_boundary = -(b + w[0]*x1)/w[1]\n",
    "\n",
    "    shifting_factor_for_margin = 1/w[1]\n",
    "    upper_margin = decision_boundary + shifting_factor_for_margin\n",
    "    lower_margin = decision_boundary - shifting_factor_for_margin\n",
    "\n",
    "    svs = svm_clf.support_vectors_\n",
    "    plt.scatter(svs[:, 0], svs[:, 1], s=200, facecolors='g', label=\"Support Vectors\")\n",
    "    plt.plot(x1, decision_boundary, \"k-\", linewidth=2)\n",
    "    plt.plot(x1, upper_margin, \"k--\", linewidth=2)\n",
    "    plt.plot(x1, lower_margin, \"k--\", linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_boundary_svc_class_colored(clf, X, plotDistanceFromHyperplane=False, colorBar=False):\n",
    "    \n",
    "    # Get the min and max value of feature x1\n",
    "    x1min, x1max = X[:,0].min() - 1, X[:, 0].max() + 1\n",
    "    \n",
    "    # Get the min and max value of feature x2\n",
    "    x2min, x2max = X[:,1].min() - 1, X[:, 1].max() + 1\n",
    "    \n",
    "    # Create the mesh grid\n",
    "    x1s = np.linspace(x1min, x1max, 100)\n",
    "    x2s = np.linspace(x2min, x2max, 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    \n",
    "    \n",
    "    # Create pairs of new points from the grid\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    \n",
    "    \n",
    "    # Compute the class predictions for all new points\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    \n",
    "    \n",
    "    # Generate the contourf plot for the predictions\n",
    "    plt.contourf(x1, x2, y_pred, cmap=plt.cm.bwr, alpha=0.2)\n",
    "    \n",
    "    \n",
    "    if(plotDistanceFromHyperplane == True):\n",
    "    \n",
    "        # Compute the signed distance of a sample to the hyperplane for all new points\n",
    "        y_decision = clf.decision_function(X_new).reshape(x1.shape)\n",
    "\n",
    "        # Generate the contour plot for the distance of all points from the hyperplane and the two margins\n",
    "        plt.contour(x1, x2, y_decision, levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'], colors='black')\n",
    "        \n",
    "        \n",
    "        #plt.pcolormesh(x1, x2, -y_decision, cmap=plt.cm.RdBu)\n",
    "        \n",
    "        # Generate the contourf plot for the distance of all points from the hyperplane\n",
    "        plt.contourf(x1, x2, y_decision, cmap=plt.cm.bwr, alpha=0.2)\n",
    "    \n",
    "    \n",
    "    if(colorBar==True):\n",
    "        plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40933868, -0.12832676,  1.16123879, ...,  1.90521266,\n",
       "        -0.47572371, -0.13130595],\n",
       "       [-1.50294336,  1.97987605, -1.57628854, ..., -0.80413505,\n",
       "        -0.47572371, -0.13130595],\n",
       "       [-0.04480378,  0.92577464, -0.8919067 , ...,  1.22787574,\n",
       "        -0.47572371, -0.13130595],\n",
       "       ...,\n",
       "       [ 0.68426601,  0.92577464,  0.99014333, ..., -0.12679812,\n",
       "        -0.47572371, -0.13130595],\n",
       "       [ 1.4133358 , -1.39324844,  0.3057615 , ..., -0.12679812,\n",
       "        -0.47572371, -0.13130595],\n",
       "       [ 1.4133358 , -0.86619774, -0.20752487, ...,  0.55053881,\n",
       "        -0.47572371, -0.13130595]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = compute_support_vectors(LinSVC, scaler, X_train, y_train)\n",
    "svm_clf.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (1, 1, 1, 1, 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-199006e3154f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# We can plot the support vectors on the margin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdecision_boundary_support_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-b14f5eb8dd40>\u001b[0m in \u001b[0;36mdecision_boundary_support_vectors\u001b[1;34m(svm_clf, X)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0msvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfacecolors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Support Vectors\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecision_boundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"k-\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupper_margin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"k--\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower_margin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"k--\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2838\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2839\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2840\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   2841\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2842\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (1, 1, 1, 1, 100)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(121)\n",
    "\n",
    "\n",
    "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bo\", label=\"Class 0\")\n",
    "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"ro\", label=\"Class 1\")\n",
    "\n",
    "#decision_boundary_svc_class_colored(svm_clf, X_train, plotDistanceFromHyperplane=True, colorBar=False)\n",
    "\n",
    "# We can plot the support vectors on the margin\n",
    "decision_boundary_support_vectors(svm_clf, X_train)\n",
    "\n",
    "plt.xlabel(\"x1\", fontsize=14)\n",
    "plt.ylabel(\"x2\", fontsize=14)\n",
    "plt.legend(loc=\"best\", fontsize=14)\n",
    "plt.title(\"LinearSVC Classifier: $C = {}$\".format(svm_clf.C), fontsize=16)\n",
    "plt.axis([0.4, 1, 4, 8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
