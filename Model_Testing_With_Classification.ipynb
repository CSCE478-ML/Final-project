{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet,SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score,accuracy_score,mean_absolute_error\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point</th>\n",
       "      <th>Trees</th>\n",
       "      <th>Shrubs</th>\n",
       "      <th>Peren_FG</th>\n",
       "      <th>bare_groun</th>\n",
       "      <th>Annual_FG</th>\n",
       "      <th>ppt</th>\n",
       "      <th>vpdmin</th>\n",
       "      <th>vpdmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>...</th>\n",
       "      <th>aspect</th>\n",
       "      <th>Runoff</th>\n",
       "      <th>Frosting_R</th>\n",
       "      <th>Flooding_F</th>\n",
       "      <th>BD_depth</th>\n",
       "      <th>AWS_50cm</th>\n",
       "      <th>AWS_25cm</th>\n",
       "      <th>AWS_150cm</th>\n",
       "      <th>AWS_100cm</th>\n",
       "      <th>Min_WTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>1003.760</td>\n",
       "      <td>8.6440</td>\n",
       "      <td>149.085</td>\n",
       "      <td>49.1187</td>\n",
       "      <td>...</td>\n",
       "      <td>180.0860</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4900</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.4300</td>\n",
       "      <td>22.9200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>822.610</td>\n",
       "      <td>8.9776</td>\n",
       "      <td>138.599</td>\n",
       "      <td>46.5965</td>\n",
       "      <td>...</td>\n",
       "      <td>211.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>849.481</td>\n",
       "      <td>9.4117</td>\n",
       "      <td>138.963</td>\n",
       "      <td>47.8117</td>\n",
       "      <td>...</td>\n",
       "      <td>186.5640</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>854.956</td>\n",
       "      <td>8.1519</td>\n",
       "      <td>135.181</td>\n",
       "      <td>45.4194</td>\n",
       "      <td>...</td>\n",
       "      <td>161.3930</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>849.242</td>\n",
       "      <td>9.2913</td>\n",
       "      <td>138.704</td>\n",
       "      <td>47.6300</td>\n",
       "      <td>...</td>\n",
       "      <td>121.3640</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4792</th>\n",
       "      <td>4793</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>789.471</td>\n",
       "      <td>12.5005</td>\n",
       "      <td>176.244</td>\n",
       "      <td>69.1463</td>\n",
       "      <td>...</td>\n",
       "      <td>297.1450</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1439</td>\n",
       "      <td>1.0640</td>\n",
       "      <td>6.4935</td>\n",
       "      <td>4.3117</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>4794</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>778.307</td>\n",
       "      <td>8.1716</td>\n",
       "      <td>180.426</td>\n",
       "      <td>41.2986</td>\n",
       "      <td>...</td>\n",
       "      <td>25.7692</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>4795</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>706.038</td>\n",
       "      <td>9.8153</td>\n",
       "      <td>175.318</td>\n",
       "      <td>46.5239</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0057</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>4796</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>713.786</td>\n",
       "      <td>13.5313</td>\n",
       "      <td>179.063</td>\n",
       "      <td>65.2216</td>\n",
       "      <td>...</td>\n",
       "      <td>68.3994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1172</td>\n",
       "      <td>1.1507</td>\n",
       "      <td>4.5539</td>\n",
       "      <td>3.3355</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>4797</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>710.399</td>\n",
       "      <td>9.0785</td>\n",
       "      <td>175.871</td>\n",
       "      <td>44.7851</td>\n",
       "      <td>...</td>\n",
       "      <td>196.9770</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.4794</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4797 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Point  Trees  Shrubs  Peren_FG  bare_groun  Annual_FG       ppt  \\\n",
       "0         1     19       8        47           7         22  1003.760   \n",
       "1         2      2       1        66          14          8   822.610   \n",
       "2         3      3       1        69           2         14   849.481   \n",
       "3         4     20       4        51          11         21   854.956   \n",
       "4         5     18      11        50           9         20   849.242   \n",
       "...     ...    ...     ...       ...         ...        ...       ...   \n",
       "4792   4793     13       8        57          15         23   789.471   \n",
       "4793   4794     36       7        43           1         12   778.307   \n",
       "4794   4795     36       9        53           2         13   706.038   \n",
       "4795   4796     33       4        43           3         11   713.786   \n",
       "4796   4797     13       7        57          10         13   710.399   \n",
       "\n",
       "       vpdmin   vpdmax     tmin  ...    aspect  Runoff  Frosting_R  \\\n",
       "0      8.6440  149.085  49.1187  ...  180.0860       3           3   \n",
       "1      8.9776  138.599  46.5965  ...  211.4610       1           3   \n",
       "2      9.4117  138.963  47.8117  ...  186.5640       1           3   \n",
       "3      8.1519  135.181  45.4194  ...  161.3930       1           3   \n",
       "4      9.2913  138.704  47.6300  ...  121.3640       1           3   \n",
       "...       ...      ...      ...  ...       ...     ...         ...   \n",
       "4792  12.5005  176.244  69.1463  ...  297.1450       0          -1   \n",
       "4793   8.1716  180.426  41.2986  ...   25.7692       6           2   \n",
       "4794   9.8153  175.318  46.5239  ...   21.0057       6           2   \n",
       "4795  13.5313  179.063  65.2216  ...   68.3994       0           0   \n",
       "4796   9.0785  175.871  44.7851  ...  196.9770      -1          -1   \n",
       "\n",
       "      Flooding_F  BD_depth  AWS_50cm  AWS_25cm  AWS_150cm  AWS_100cm  Min_WTD  \n",
       "0              3       0.0   11.4900    5.7500    33.4300    22.9200    153.0  \n",
       "1              3       0.0   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "2              3       0.0   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "3              3       0.0   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "4              3       0.0   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "...          ...       ...       ...       ...        ...        ...      ...  \n",
       "4792           0       0.0    2.1439    1.0640     6.4935     4.3117      0.0  \n",
       "4793           1      38.0    3.9900    2.5500     3.9900     3.9900      0.0  \n",
       "4794           1      38.0    3.9900    2.5500     3.9900     3.9900      0.0  \n",
       "4795           0       0.0    2.1172    1.1507     4.5539     3.3355      0.0  \n",
       "4796          -1       0.0    0.2470    0.1402     0.4794     0.3636      0.0  \n",
       "\n",
       "[4797 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df.values.ravel() == -1).reshape(df.shape).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point</th>\n",
       "      <th>Trees</th>\n",
       "      <th>Shrubs</th>\n",
       "      <th>Peren_FG</th>\n",
       "      <th>bare_groun</th>\n",
       "      <th>Annual_FG</th>\n",
       "      <th>ppt</th>\n",
       "      <th>vpdmin</th>\n",
       "      <th>vpdmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>...</th>\n",
       "      <th>aspect</th>\n",
       "      <th>Runoff</th>\n",
       "      <th>Frosting_R</th>\n",
       "      <th>Flooding_F</th>\n",
       "      <th>BD_depth</th>\n",
       "      <th>AWS_50cm</th>\n",
       "      <th>AWS_25cm</th>\n",
       "      <th>AWS_150cm</th>\n",
       "      <th>AWS_100cm</th>\n",
       "      <th>Min_WTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>1003.760</td>\n",
       "      <td>8.6440</td>\n",
       "      <td>149.085</td>\n",
       "      <td>49.1187</td>\n",
       "      <td>...</td>\n",
       "      <td>180.0860</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.4900</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.4300</td>\n",
       "      <td>22.9200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>822.610</td>\n",
       "      <td>8.9776</td>\n",
       "      <td>138.599</td>\n",
       "      <td>46.5965</td>\n",
       "      <td>...</td>\n",
       "      <td>211.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>849.481</td>\n",
       "      <td>9.4117</td>\n",
       "      <td>138.963</td>\n",
       "      <td>47.8117</td>\n",
       "      <td>...</td>\n",
       "      <td>186.5640</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>854.956</td>\n",
       "      <td>8.1519</td>\n",
       "      <td>135.181</td>\n",
       "      <td>45.4194</td>\n",
       "      <td>...</td>\n",
       "      <td>161.3930</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>849.242</td>\n",
       "      <td>9.2913</td>\n",
       "      <td>138.704</td>\n",
       "      <td>47.6300</td>\n",
       "      <td>...</td>\n",
       "      <td>121.3640</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>33.3200</td>\n",
       "      <td>22.8200</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>4791</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>828.338</td>\n",
       "      <td>8.7542</td>\n",
       "      <td>180.391</td>\n",
       "      <td>42.9977</td>\n",
       "      <td>...</td>\n",
       "      <td>269.6360</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>5.1000</td>\n",
       "      <td>4.2500</td>\n",
       "      <td>5.1000</td>\n",
       "      <td>5.1000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>4792</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>868.329</td>\n",
       "      <td>8.8903</td>\n",
       "      <td>176.260</td>\n",
       "      <td>40.5698</td>\n",
       "      <td>...</td>\n",
       "      <td>301.8970</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40.1869</td>\n",
       "      <td>4.1027</td>\n",
       "      <td>2.5825</td>\n",
       "      <td>4.4481</td>\n",
       "      <td>4.3668</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>4794</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>778.307</td>\n",
       "      <td>8.1716</td>\n",
       "      <td>180.426</td>\n",
       "      <td>41.2986</td>\n",
       "      <td>...</td>\n",
       "      <td>25.7692</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>4795</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>706.038</td>\n",
       "      <td>9.8153</td>\n",
       "      <td>175.318</td>\n",
       "      <td>46.5239</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0057</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>4796</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>713.786</td>\n",
       "      <td>13.5313</td>\n",
       "      <td>179.063</td>\n",
       "      <td>65.2216</td>\n",
       "      <td>...</td>\n",
       "      <td>68.3994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.1172</td>\n",
       "      <td>1.1507</td>\n",
       "      <td>4.5539</td>\n",
       "      <td>3.3355</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4180 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Point  Trees  Shrubs  Peren_FG  bare_groun  Annual_FG       ppt  \\\n",
       "0         1     19       8        47           7         22  1003.760   \n",
       "1         2      2       1        66          14          8   822.610   \n",
       "2         3      3       1        69           2         14   849.481   \n",
       "3         4     20       4        51          11         21   854.956   \n",
       "4         5     18      11        50           9         20   849.242   \n",
       "...     ...    ...     ...       ...         ...        ...       ...   \n",
       "4790   4791     51       7        43           3         10   828.338   \n",
       "4791   4792     17       7        67           1         10   868.329   \n",
       "4793   4794     36       7        43           1         12   778.307   \n",
       "4794   4795     36       9        53           2         13   706.038   \n",
       "4795   4796     33       4        43           3         11   713.786   \n",
       "\n",
       "       vpdmin   vpdmax     tmin  ...    aspect  Runoff  Frosting_R  \\\n",
       "0      8.6440  149.085  49.1187  ...  180.0860       3           3   \n",
       "1      8.9776  138.599  46.5965  ...  211.4610       1           3   \n",
       "2      9.4117  138.963  47.8117  ...  186.5640       1           3   \n",
       "3      8.1519  135.181  45.4194  ...  161.3930       1           3   \n",
       "4      9.2913  138.704  47.6300  ...  121.3640       1           3   \n",
       "...       ...      ...      ...  ...       ...     ...         ...   \n",
       "4790   8.7542  180.391  42.9977  ...  269.6360       5           2   \n",
       "4791   8.8903  176.260  40.5698  ...  301.8970       6           2   \n",
       "4793   8.1716  180.426  41.2986  ...   25.7692       6           2   \n",
       "4794   9.8153  175.318  46.5239  ...   21.0057       6           2   \n",
       "4795  13.5313  179.063  65.2216  ...   68.3994       0           0   \n",
       "\n",
       "      Flooding_F  BD_depth  AWS_50cm  AWS_25cm  AWS_150cm  AWS_100cm  Min_WTD  \n",
       "0              3    0.0000   11.4900    5.7500    33.4300    22.9200    153.0  \n",
       "1              3    0.0000   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "2              3    0.0000   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "3              3    0.0000   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "4              3    0.0000   11.5000    5.7500    33.3200    22.8200    153.0  \n",
       "...          ...       ...       ...       ...        ...        ...      ...  \n",
       "4790           1   38.0000    5.1000    4.2500     5.1000     5.1000      0.0  \n",
       "4791           1   40.1869    4.1027    2.5825     4.4481     4.3668      0.0  \n",
       "4793           1   38.0000    3.9900    2.5500     3.9900     3.9900      0.0  \n",
       "4794           1   38.0000    3.9900    2.5500     3.9900     3.9900      0.0  \n",
       "4795           0    0.0000    2.1172    1.1507     4.5539     3.3355      0.0  \n",
       "\n",
       "[4180 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(frac=1) #Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Trees']= (df['Trees'] > 40).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Trees']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_mse = ['Shrubs', 'Peren_FG', 'bare_groun', 'Annual_FG', 'vpdmax', 'tmean',\n",
    "       'slope', 'Runoff', 'Flooding_F', 'BD_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = df[best_feature_mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(best_df)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3344, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Degree:  1\n"
     ]
    }
   ],
   "source": [
    "degreeList = [1,2,3,4,5,6]\n",
    "\n",
    "\n",
    "mse_train, mse_test = [], []\n",
    "\n",
    "for degree in degreeList:\n",
    "\n",
    "    model = make_pipeline(PolynomialFeatures(degree, include_bias=False), StandardScaler(), LinearRegression()) \n",
    "  \n",
    "    model.fit(X_train, y_train)\n",
    "       \n",
    "    # Make prediction \n",
    "    y_train_predicted = model.predict(X_train)\n",
    "    y_test_predicted = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    mse_train.append(mean_squared_error(y_train, y_train_predicted))\n",
    "    mse_test.append(mean_squared_error(y_test, y_test_predicted))\n",
    "   \n",
    "\n",
    "plt.figure(figsize=(10, 6))   \n",
    "plt.plot(degreeList, np.sqrt(mse_test), \"ro-\", alpha=1.0, linewidth=1.0, label=\"Test RMSE\")\n",
    "plt.plot(degreeList, np.sqrt(mse_train), \"bo-\", alpha=1.0, linewidth=1.0, label=\"Train RMSE\") \n",
    "plt.legend(loc=\"best\", fontsize=14) \n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"RMSE for Varying Degree\")\n",
    "plt.show()\n",
    "\n",
    "# Find the value of optimal degree for the polynomial that gives smallest RMSE\n",
    "\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "j = 0\n",
    "min_rmse = rmse_test[j]\n",
    "optimal_degree = 1\n",
    "\n",
    "for i in degreeList:\n",
    "    if(rmse_test[j] < min_rmse):\n",
    "        min_rmse = rmse_test[j]\n",
    "        optimal_degree = i\n",
    "    j +=1\n",
    "    \n",
    "print(\"\\nOptimal Degree: \", optimal_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable that speficies the degree of the polynomial to be added to the feature vector\n",
    "poly_degree = optimal_degree\n",
    "\n",
    "\n",
    "# Add polynomial terms with the feature vector using the sklearn PolynomialFeatures class\n",
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Original Features:  10\n",
      "No. of Augmented Features:  10\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of Original Features: \", X_train.shape[1])\n",
    "print(\"No. of Augmented Features: \", X_train_poly.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values \n",
    "param_grid = {'n_neighbors': np.arange(1, 37, 2), 'p': [1, 2, 5, 10, 20, 30, 50, 100], \n",
    "              'weights': [\"uniform\", \"distance\"]}\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "knn_cv = GridSearchCV(knn_clf, param_grid, scoring='f1', cv=5, verbose=3, n_jobs=-1)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "params_optimal_knn = knn_cv.best_params_\n",
    "\n",
    "print(\"Best Score: %f\" % knn_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_knn)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(**params_optimal_knn)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_train_predicted = knn.predict(X_train)\n",
    "\n",
    "train_accuracy_knn = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "# Note: For a skewed data set \"accuracy\" might not be a good choice for scoring\n",
    "scores = cross_val_score(knn, X_train, y_train, scoring='f1', cv=5)\n",
    "print(scores)\n",
    "\n",
    "print(\"F1 Score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(knn, X_train, y_train, cv=5)\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precision = precision_score(y_train, y_train_pred) \n",
    "print(\"Precision = %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_train, y_train_pred)\n",
    "print(\"Recall = %f\" % recall)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "print(\"F1 Score = %f\" % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 2nd column of the matrix of predicted probabilities for each data point\n",
    "#    The 2nd column stores the probalities of the positive class\n",
    "y_scores = cross_val_predict(knn, X_train, y_train, method=\"predict_proba\", cv=5)[:, 1]\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_scores)\n",
    "\n",
    "print(\"\\nFPR FPR & TPR for Various Threshold Values:\")\n",
    "\n",
    "print(\"FPR: \", fpr)\n",
    "print(\"TPR: \", tpr)\n",
    "print(\"\\nThresholds: \", thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "def plot_roc_curve(fpr, tpr, label=None): \n",
    "    plt.plot(fpr, tpr, color='darkorange', linewidth=8, label=label) \n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.title('ROC Curve (Train Data)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area under ROC curve\n",
    "roc_auc_score(y_train,y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "# Get the 2nd column of the matrix of predicted probabilities for each data point\n",
    "#    The 2nd column stores the probalities of the positive class\n",
    "y_scores = cross_val_predict(knn, X_train, y_train, method=\"predict_proba\", cv=3)[:, 1]\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds): \n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\",  linewidth=8, label=\"Precision\") \n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\",  linewidth=3, label=\"Recall\") \n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    #plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1.1])\n",
    "\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "threshold_optimal = 0.5\n",
    "for i in range(len(precisions)):\n",
    "    if(abs(abs(precisions[i]) - abs(recalls[i]))<=0.005):\n",
    "        threshold_optimal = thresholds[i]\n",
    "\n",
    "print(\"Optimal Threshold: \", threshold_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use variable threshold.\n",
    "print(\"Performance Measures Based on the Default Threshold:\\n\")\n",
    "\n",
    "\n",
    "y_train_pred = cross_val_predict(knn, X_train, y_train, cv=5)\n",
    "\n",
    "# Precision, Recall, F1 Score and Confusion Matrix for the Default Threshold 0.5\n",
    "precision_train = precision_score(y_train, y_train_pred) \n",
    "print(\"Precision (Default Threshold 0.5) = %f\" % precision_train)\n",
    "\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "print(\"Recall (Default Threshold 0.5) = %f\" % recall_train)\n",
    "\n",
    "\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "print(\"F1 Score (Default Threshold 0.5) = %f\" % f1_train)\n",
    "\n",
    "print(\"Confusion Matrix (Default Threshold 0.5)\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "print(\"\\n-------------------------------------------------------\\n\")\n",
    "print(\"Performance Measures Based on the Optimal Threshold (from Precision-Recall Curve):\")\n",
    "\n",
    "# Precision, Recall, F1 Score and Confusion Matrix for different threshold\n",
    "\n",
    "t = threshold_optimal # optimal threshold from precision-recall curve \n",
    "\n",
    "# Compute predictions based on new t by using the following method:\n",
    "#  - Get the probability of the positive class from the 2nd column [:, 1]\n",
    "#  - If that probability is greater than or equal to t, then the test data belongs to the positive class\n",
    "y_train_predicted_new = (cross_val_predict(knn, X_train, y_train, method=\"predict_proba\", cv=3)[:,1] > t).astype(int)\n",
    "\n",
    "\n",
    "precision = precision_score(y_train, y_train_predicted_new) \n",
    "print(\"\\nPrecision (Threshold %.2f) = %f\" % (t, precision))\n",
    "\n",
    "recall = recall_score(y_train, y_train_predicted_new)\n",
    "print(\"Recall (Threshold %.2f) = %f\" % (t, recall))\n",
    "\n",
    "\n",
    "f1 = f1_score(y_train, y_train_predicted_new)\n",
    "print(\"F1 Score = (Threshold %.2f) = %f\" % (t, f1))\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix (Threshold %.2f)\" %  t) \n",
    "print(confusion_matrix(y_train, y_train_predicted_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The accuracy of the model\n",
    "test_accuracy_knn = knn.score(X_test, y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_knn)\n",
    "\n",
    "\n",
    "# No. of Correct Predictions\n",
    "y_test_predicted = knn.predict(X_test)\n",
    "print(\"\\nNo. of correct predictions (Test): %d/%d\" % (np.sum(y_test_predicted == y_test), len(y_test)))\n",
    "\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_test_predicted) \n",
    "print(\"Precision = %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_test, y_test_predicted)\n",
    "print(\"Recall = %f\" % recall)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test, y_test_predicted)\n",
    "print(\"F1 Score = %f\" % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the 2nd column of the matrix of predicted probabilities for each data point\n",
    "#    The 2nd column stores the probalities of the positive class\n",
    "y_scores_test = cross_val_predict(knn, X_test, y_test, method=\"predict_proba\", cv=3)[:, 1]\n",
    "\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_scores_test)\n",
    "\n",
    "\n",
    "print(\"\\nFPR FPR & TPR for Various Threshold Values:\")\n",
    "print(\"FPR: \", fpr_test)\n",
    "print(\"TPR: \", tpr_test)\n",
    "print(\"\\nThresholds: \", thresholds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plot_roc_curve(fpr_test, tpr_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area under ROC curve\n",
    "roc_auc_score(y_test,y_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "param_grid = {'var_smoothing': [0.001, 0.01, 0.1, 1.0]}\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb = GridSearchCV(gnb, param_grid, scoring='accuracy', cv=10, verbose=1, n_jobs=-1)\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "params_optimal = gnb.best_params_\n",
    "\n",
    "print(\"Best Score (accuracy): %f\" % gnb.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gaussianNB_clf = GaussianNB(**params_optimal)\n",
    "\n",
    "gaussianNB_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 2nd column of the matrix of predicted probabilities for each data point\n",
    "#    The 2nd column stores the probalities of the positive class\n",
    "y_scores_test = cross_val_predict(gnb, X_test, y_test, method=\"predict_proba\", cv=3)[:, 1]\n",
    "\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_scores_test)\n",
    "\n",
    "\n",
    "print(\"\\nFPR FPR & TPR for Various Threshold Values:\")\n",
    "print(\"FPR: \", fpr_test)\n",
    "print(\"TPR: \", tpr_test)\n",
    "print(\"\\nThresholds: \", thresholds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plot_roc_curve(fpr_test, tpr_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area under ROC curve\n",
    "roc_auc_score(y_test,y_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted = gaussianNB_clf.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_score_test = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nAccuracy: \", accuracy_score_test)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average='micro') \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"\\nTest Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"\\nTest F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive-Bayes Classifier NO GOOD OUT\n",
    "NOTES: CURRENT TEST DATA WILL NOT RUN WITH MULTINOMIAL NB, DUE TO THE X_train dataset having negative values. THus, I have input the absolute value of X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "param_grid = {'alpha': [0.000001, 0.00001, 0.0001, 0.01]}\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "\n",
    "mnb = GridSearchCV(mnb, param_grid, scoring='accuracy', cv=10, verbose=1, n_jobs=-1)\n",
    "\n",
    "mnb.fit(abs(X_train), y_train)\n",
    "\n",
    "params_optimal = mnb.best_params_\n",
    "\n",
    "print(\"Best Score (accuracy): %f\" % mnb.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "multinomialNB_clf = MultinomialNB(**params_optimal)\n",
    "\n",
    "multinomialNB_clf.fit(abs(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 2nd column of the matrix of predicted probabilities for each data point\n",
    "#    The 2nd column stores the probalities of the positive class\n",
    "y_scores_test = cross_val_predict(mnb, abs(X_test), y_test, method=\"predict_proba\", cv=3)[:, 1]\n",
    "\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_scores_test)\n",
    "\n",
    "\n",
    "print(\"\\nFPR FPR & TPR for Various Threshold Values:\")\n",
    "print(\"FPR: \", fpr_test)\n",
    "print(\"TPR: \", tpr_test)\n",
    "print(\"\\nThresholds: \", thresholds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plot_roc_curve(fpr_test, tpr_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area under ROC curve\n",
    "roc_auc_score(y_test,y_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test_predicted_mnb = multinomialNB_clf.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_score_test = np.mean(y_test_predicted_mnb == y_test)\n",
    "print(\"\\nAccuracy: \", accuracy_score_test)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted_mnb))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted_mnb, average='micro') \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted_mnb, average='micro')\n",
    "print(\"\\nTest Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted_mnb, average='micro')\n",
    "print(\"\\nTest F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted_mnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC (Current optimal with current data processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LinSVC = LinearSVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "param_grid = {\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C' : [ 1 , 35, 50, 100, 500, 1000],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'tol' : [0.1 , 0.01, 0.001, 0.0001],\n",
    "    'max_iter' : [10, 35, 50, 100, 500, 1000, 5000, 10000],\n",
    "}\n",
    "\n",
    "LinSVC_cv = GridSearchCV(LinSVC, param_grid, scoring='accuracy', cv=5)\n",
    "\n",
    "LinSVC_cv = LinSVC_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Score: %f\" % LinSVC_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, LinSVC_cv.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LinSVC= LinearSVC(random_state=42, C=LinSVC_cv.best_params_['C'], loss=LinSVC_cv.best_params_['loss'], max_iter=LinSVC_cv.best_params_['max_iter'], penalty= LinSVC_cv.best_params_['penalty'], tol=LinSVC_cv.best_params_['tol']).fit(X_train, y_train)\n",
    "LinSVC.fit(X_train, y_train)\n",
    "\n",
    "y_train_predicted = LinSVC.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"Training Accuracy: \", LinSVC.score(X_train, y_train))\n",
    "y_test_predicted = LinSVC.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Test Accuracy: \", LinSVC.score(X_test, y_test))\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted) \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted)\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted)\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC: Polynomial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fold, X_val_fold, y_train_fold, y_val_fold = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall find the optimal degree, using our best LinearSVC model hyperperameters, for our polynomial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "degreeList = [1,2,3,4,5,6]\n",
    "accuracy_train, accuracy_val = [], []\n",
    "\n",
    "for degree in degreeList:\n",
    "    model = make_pipeline(PolynomialFeatures(degree, include_bias=False), StandardScaler(), \n",
    "                          LinearSVC(random_state=42, C=LinSVC_cv.best_params_['C'], loss=LinSVC_cv.best_params_['loss'], max_iter=LinSVC_cv.best_params_['max_iter'], penalty= LinSVC_cv.best_params_['penalty'], tol=LinSVC_cv.best_params_['tol'])) \n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "       \n",
    "    # Make prediction \n",
    "    y_train_predicted = model.predict(X_train_fold)\n",
    "    y_val_predicted = model.predict(X_val_fold)\n",
    "    \n",
    "    accuracy_train.append(model.score(X_train_fold, y_train_fold))\n",
    "    accuracy_val.append(model.score(X_val_fold, y_val_fold))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))   \n",
    "plt.plot(degreeList, accuracy_val, \"ro-\", alpha=1.0, linewidth=1.0, label=\"Validation Accuracy\")\n",
    "plt.plot(degreeList, accuracy_train, \"bo-\", alpha=1.0, linewidth=1.0, label=\"Train Accuracy\")  \n",
    "\n",
    "plt.legend(loc=\"best\", fontsize=14) \n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy for Varying Degree\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Find the value of degree that gives max validation accuracy\n",
    "j = 0\n",
    "max_val_accuracy = accuracy_val[j]\n",
    "optimal_degree = 1\n",
    "\n",
    "for i in degreeList:\n",
    "    if(accuracy_val[j] > max_val_accuracy):\n",
    "        max_val_accuracy = accuracy_val[j]\n",
    "        optimal_degree = i\n",
    "    j +=1\n",
    "    \n",
    "print(\"Optimal Degree: \", optimal_degree)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable that speficies the degree of the polynomial to be added to the feature vector\n",
    "optimal_poly_degree = optimal_degree\n",
    "\n",
    "\n",
    "scaled_svm_clf = Pipeline([\n",
    "        (\"poly_features\", PolynomialFeatures(degree=optimal_poly_degree)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LinearSVC(random_state=42, C=LinSVC_cv.best_params_['C'], loss=LinSVC_cv.best_params_['loss'], max_iter=LinSVC_cv.best_params_['max_iter'], penalty= LinSVC_cv.best_params_['penalty'], tol=LinSVC_cv.best_params_['tol']))\n",
    "    ])\n",
    "\n",
    "\n",
    "scaled_svm_clf.fit(X, y)\n",
    "\n",
    "y_train_predicted = scaled_svm_clf.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"Training Accuracy: \", scaled_svm_clf.score(X_train, y_train))\n",
    "\n",
    "y_test_predicted = scaled_svm_clf.predict(X_test)\n",
    "print(\"Test Accuracy: \", scaled_svm_clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted) \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted)\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted)\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC -> Kernelized SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC: Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'C' : [ 1 , 35, 50, 100, 500, 1000],\n",
    "    'tol' : [0.1 , 0.01, 0.001, 0.0001],\n",
    "    'max_iter' : [10, 35, 50, 100, 500, 1000],\n",
    "}\n",
    "\n",
    "svc_clf_cv = GridSearchCV(svc_clf, param_grid, scoring='accuracy', cv=5)\n",
    "\n",
    "svc_clf_cv = svc_clf_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Score: %f\" % svc_clf_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, svc_clf_cv.best_params_[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = SVC(kernel='linear', C= svc_clf_cv.best_params_['C'], tol= svc_clf_cv.best_params_['tol'], gamma= svc_clf_cv.best_params_['gamma'], max_iter= svc_clf_cv.best_params_['max_iter'], ).fit(X_train, y_train)\n",
    "\n",
    "svc_clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_predicted = svc_clf.predict(X_train)\n",
    "\n",
    "print(\"Training Accuracy: \", svc_clf.score(X_train, y_train))\n",
    "y_test_predicted = svc_clf.predict(X_test)\n",
    "print(\"Test Accuracy: \", svc_clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted) \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted)\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted)\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC: Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_poly_clf = SVC(kernel='poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'C' : [ 1 , 35, 50, 100, 500, 1000],\n",
    "    'degree' : [1, 2, 3, 4, 5, 6],\n",
    "    'tol' : [0.1 , 0.01, 0.001, 0.0001],\n",
    "    'max_iter' : [10, 35, 50, 100, 500, 1000],\n",
    "}\n",
    "\n",
    "svc_poly_clf_cv = GridSearchCV(svc_poly_clf, param_grid, scoring='accuracy', cv=5)\n",
    "\n",
    "svc_poly_clf_cv = svc_poly_clf_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Score: %f\" % svc_poly_clf_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, svc_poly_clf_cv.best_params_[param_name]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "degreeList = [1,2,3,4,5,6]\n",
    "accuracy_train, accuracy_val = [], []\n",
    "\n",
    "for degree in degreeList:\n",
    "    model = SVC(C=svc_poly_clf_cv.best_params_['C'], kernel='poly', degree=degree, gamma= svc_poly_clf_cv.best_params_['gamma'], max_iter= svc_poly_clf_cv.best_params_['max_iter'], tol= svc_poly_clf_cv.best_params_['tol'])\n",
    "  \n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "       \n",
    "    # Make prediction \n",
    "    y_train_predicted = model.predict(X_train_fold)\n",
    "    y_val_predicted = model.predict(X_val_fold)\n",
    "    \n",
    "    \n",
    "    accuracy_train.append(model.score(X_train_fold, y_train_fold))\n",
    "    accuracy_val.append(model.score(X_val_fold, y_val_fold))\n",
    "      \n",
    "\n",
    "plt.figure(figsize=(10, 6))   \n",
    "plt.plot(degreeList, accuracy_val, \"ro-\", alpha=1.0, linewidth=1.0, label=\"Validation Accuracy\")\n",
    "plt.plot(degreeList, accuracy_train, \"bo-\", alpha=1.0, linewidth=1.0, label=\"Train Accuracy\")  \n",
    "\n",
    "plt.legend(loc=\"best\", fontsize=14) \n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy for Varying Degree\")\n",
    "plt.show()\n",
    "\n",
    "# Find the value of degree that gives max validation accuracy\n",
    "j = 0\n",
    "max_val_accuracy = accuracy_val[j]\n",
    "optimal_degree = 1\n",
    "\n",
    "for i in degreeList:\n",
    "    if(accuracy_val[j] > max_val_accuracy):\n",
    "        max_val_accuracy = accuracy_val[j]\n",
    "        optimal_degree = i\n",
    "    j +=1\n",
    "    \n",
    "print(\"Optimal Degree: \", optimal_degree)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = SVC(C=svc_poly_clf_cv.best_params_['C'], kernel='poly', degree=optimal_degree, gamma= svc_poly_clf_cv.best_params_['gamma'], max_iter= svc_poly_clf_cv.best_params_['max_iter'], tol= svc_poly_clf_cv.best_params_['tol']).fit(X_train, y_train)\n",
    "\n",
    "svc_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_train_predicted = svc_clf.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"Training Accuracy: \", svc_clf.score(X_train, y_train))\n",
    "y_test_predicted = svc_clf.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy: \", svc_clf.score(X_test, y_test))\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted) \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted)\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted)\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC: Gaussian Radial Basis Function Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_clf = SVC(kernel=\"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "param_grid = {\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'C' : [ 1 , 35, 50, 100, 500, 1000],\n",
    "    #'degree': [1,2,3,4,5,6],\n",
    "    'tol' : [0.1 , 0.01, 0.001, 0.0001],\n",
    "    'max_iter' : [10, 35, 50, 100, 500],\n",
    "}\n",
    "\n",
    "svm_sbf_cv = GridSearchCV(svm_rbf_clf, param_grid, scoring='accuracy', cv=5)\n",
    "\n",
    "svm_rbf_cv = svm_sbf_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Score: %f\" % svm_rbf_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, svm_rbf_cv.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm_rbf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_predicted = svm_rbf_clf.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"Training Accuracy: \", svm_rbf_clf.score(X_train, y_train))\n",
    "y_test_predicted = svm_rbf_clf.predict(X_test)\n",
    "print(\"Test Accuracy: \", svm_rbf_clf.score(X_test, y_test))\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted) \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted)\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted)\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM using the SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "svm_sgd = Pipeline([\n",
    "        ('clf', SGDClassifier(loss='hinge')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "param_grid = {\n",
    "    'clf__alpha': [1e-4, 1e-5],\n",
    "    'clf__penalty': ['l2', 'l1'],\n",
    "    'clf__max_iter': [10, 35, 50, 100, 500],\n",
    "    'clf__tol' : [0.1, 1, 0.01, 0.001,0.0001],\n",
    "    'clf__eta0' : [0.1, 0.01, 0.001, 0.0001],\n",
    "    'clf__learning_rate' : ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "svm_sgd_cv = GridSearchCV(svm_sgd, param_grid, scoring='accuracy', cv=5)\n",
    "\n",
    "svm_sgd_cv = svm_sgd_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Score: %f\" % svm_sgd_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, svm_sgd_cv.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "svm_sgd = Pipeline([\n",
    "        ('clf', SGDClassifier(loss='hinge', penalty=svm_sgd_cv.best_params_['clf__penalty'], alpha=svm_sgd_cv.best_params_['clf__alpha'], eta0=svm_sgd_cv.best_params_['clf__eta0'], learning_rate=svm_sgd_cv.best_params_['clf__learning_rate'], random_state=42, max_iter=svm_sgd_cv.best_params_['clf__max_iter'], tol=svm_sgd_cv.best_params_['clf__tol'])),\n",
    "    ])\n",
    "svm_sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y_test_predicted = svm_sgd.predict(X_test)\n",
    "\n",
    "print(\"\\nAccuracy: \", np.mean(y_test_predicted == y_test))\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average='micro') \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"\\nTest Recall = %f\" % recall_test)\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"\\nTest F1 Score = %f\" % f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:    3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (negative mean squared error): -27.142928\n",
      "Optimal Hyperparameter Values:  {'alpha': 0.03538461538461538, 'solver': 'saga'}\n",
      "\n",
      "\n",
      "Wall time: 3.53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2400 out of 2400 | elapsed:    3.4s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "\n",
    "param_grid = {'alpha': np.linspace(0.01, 1.0, num=40), \n",
    "              'solver': [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"saga\"]}\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "ridge_cv = GridSearchCV(ridge, param_grid, scoring='neg_mean_squared_error', cv=10, verbose=1, n_jobs=-1)\n",
    "ridge_cv.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "params_optimal_ridge = ridge_cv.best_params_\n",
    "\n",
    "print(\"Best Score (negative mean squared error): %f\" % ridge_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_ridge)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha:  0.03538461538461538\n",
      "Optimal alpha:  saga\n",
      "\n",
      "----------------------------- Model Evaluation -----------------------------\n",
      "\n",
      "Mean squared error: 26.87\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "\n",
    "# Optimal model parameters\n",
    "ridge_alpha = ridge_cv.best_params_['alpha']\n",
    "print(\"Optimal alpha: \", ridge_alpha)\n",
    "\n",
    "ridge_solver = ridge_cv.best_params_['solver']\n",
    "print(\"Optimal alpha: \", ridge_solver)\n",
    "\n",
    "\n",
    "# Create Ridge linear regression object\n",
    "lin_reg_ridge = Ridge(alpha=ridge_alpha, solver=ridge_solver)\n",
    "\n",
    "# Train the model\n",
    "lin_reg_ridge.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_ridge = lin_reg_ridge.predict(X_train_poly)\n",
    "\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_predicted_ridge))\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % r2_score(y_train, y_train_predicted_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------- Test Model Evaluation -----------------------------\n",
      "\n",
      "Mean squared error: 26.81\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.72\n",
      "[ 4  1 38  1  7 29 15 18 26  2  7 12  7 46  8 26  4  1  5 12  6  2 16  9\n",
      "  7  3 23  6 15 24  4  2 18 52  3 20 17  2 13 10  0  9 34  6  4  0  4  3\n",
      "  5 11  3 22  2  2 19  6  1 14 17 17  6  0  6 15 17  1  6  5 11 18 17 34\n",
      " 49 10  1  3 17 52  3  2  5  1  1  5  0  6  5 17 16  4 25 19 18 29 19  9\n",
      " 24  7 41 11  3  2  4  3  2 18  3 24  3 14  8 13  1  9  7 15  2  6  1  3\n",
      "  6 11  9  1  2 18 10  1 23  1 17  1  0  7 12 21 34 11 20  3 14  1 10  4\n",
      "  8  3 21  3 31  0 11 12  9  5  4 19  9  0  1  2  3 25 13  2 13  0  3  4\n",
      "  3 19 20  7 19 11  7 22  0 45 23 16  0  8  3  7  6 21 20  0 12  2  4 24\n",
      "  2 13  2 14 28  4  3  6  3 15 19 13 15  1  7  7  2  1  1 20  6 48 15 16\n",
      "  7 17 20 17 14  4 10  1  6 15  9 33  9  5 21  5 17 18 14 15  2  0 20 17\n",
      " 12  7  9  1  4  9 15 13  7  6  2  6  5  0  1  1  7 16 21  1 23  8  2  6\n",
      "  3  2  7  9 13  0  4  6  6  5 17  1 20  2 11  3  4  6  9  9 42  0 44  1\n",
      "  0 15  4  7 21  0 24  8  9  9 15  4  8  8  1 12  7  5 21  1  2 11  7  3\n",
      "  1  4  1 18  2  0  5 44 11 17  0  5  4  3  7 10  6  4 36 20 12 19 25  2\n",
      "  4  9 10 12 13 14 11  8  3  7 20  4  1  2  2  9 18  4  4 30 26  1 19 10\n",
      "  1 23  5  1  8  9 20  8  3  5  1  4 10  4  3  8  8 10 14 10 10  1  5  1\n",
      "  0  3 14 13  4 22  9 15 12 18 38 34 17  9  4 15 21 16 30 10  1  2  3  4\n",
      "  5 14  9 14 17  4 13  2  3  2  0 17  1 11 27  3  8 25  4  9 13  5  6  2\n",
      " 16 22 11 22  9 53  5 27 19  5  1 10 16 23  3  2 16  3  6 18  3  2  2  9\n",
      "  5 10  0 15  8  6  5  1  7  5  3 10  3 18  0 20  3 12 16  4  1 30  4  7\n",
      "  8  3  9 13 17  7  3 27  7  5  7  0  0 29  9 17  2 21 10  3 13 16  1  4\n",
      "  8 16  1  3  2 16 14 37  1  0  5  9 23  3 15  3  5  9 10  3 31 17  9  4\n",
      " 35 26 15 23 17  7  5 26  2  3  1 24  2 16  2 17 14 17  4 24 22  2 16 13\n",
      "  2 19 17 10  7  0 50 49  6 12 49  4  2  3  1 13 16  1  2  5 15  2 17  2\n",
      " 15 10  9  0  8  1  4  2  2  5 11 11  1  2 17 17  1 15  3  1  1  0 22  2\n",
      " 37  1  3  9 10  9  5 19 12  2 11  4  6 18 17  1  3  4  6  0  2 12  0 46\n",
      "  6 21  9 18  5  8 35  1  6 10 16  1  5  6 18 16  2 12 13  0 16  0 15 21\n",
      " 55  1  0 19  1 27 15  7 11 12  3  1  1  9  6  4  6  3 12  2 14 13  6 14\n",
      " 10 11  1 34 10  2 20 16  3  7  0 10 11 18  3 16  7 29 12  1  9  5 30 27\n",
      " 21  2 18 10  6  6 20 16 19 16 10  4  3 17 25 19 16  5 21  3  2  6 10 29\n",
      "  4  2 12  6  0 11  5  3  2  0  5 51 33  0  5  3  5  4  9  9  3  5  6 17\n",
      " 10 17 16 25 18  8  8 17  3 22  7  6 14  2 20  1  8 15  3  5  7  2  4  0\n",
      "  2  3 18  6  3 17  1  0 17  4  1  5  2 28  3  8 34 10 21 30  1 31  4 13\n",
      "  9  2  6 10  4  2 16  4  6 10  9 16  7  1  8 25 14  1 17 11 52 20  6  3\n",
      " 12  9 28  7 16  3 11 23 16  2  4  3  9  8  5  9 16 11  2  4] [ 8.89083881e+00  8.07009361e-01  2.90846769e+01 -8.03989324e-02\n",
      "  4.09818490e+00  1.94805105e+01  1.45893170e+01  7.91374067e+00\n",
      "  1.41203436e+01  5.75354588e+00  1.15358317e+01  9.36705367e+00\n",
      "  5.68944959e+00  3.70597889e+01  1.19066780e+01  1.83025248e+01\n",
      "  6.97888703e+00  7.52637543e+00  7.63306112e+00  1.01505695e+01\n",
      "  1.04737891e+01  8.90775082e+00  1.72297731e+01  9.29480942e+00\n",
      "  5.21688978e+00  4.06622578e+00  2.19988990e+01  5.84070405e+00\n",
      "  1.23623663e+01  2.39488637e+01  9.39078526e+00  8.13270517e+00\n",
      "  1.39295570e+01  4.00640476e+01  1.35416076e+00  1.49495783e+01\n",
      "  2.01117353e+01  6.42278018e+00  1.43555285e+01  1.00610668e+01\n",
      " -3.26863908e+00  4.55154281e+00  1.72068957e+01  7.50082237e+00\n",
      "  1.80649828e+00  6.69992232e-01  6.80798448e+00  5.34280096e+00\n",
      "  9.76867861e+00  3.52701516e+00  4.43395313e+00  1.91077153e+01\n",
      "  1.00399853e+00  5.23188262e+00  1.68565530e+01  1.05026893e+01\n",
      "  2.79081480e+00  1.72011100e+01  2.07769337e+01  1.05929656e+01\n",
      "  9.86858197e+00 -1.68817837e+00  1.14326492e+01  1.93654180e+01\n",
      "  2.10009444e+01  2.60206825e+00  8.04325054e+00  5.29152597e+00\n",
      "  1.19519451e+01  1.36018831e+01  1.84638606e+01  2.30245085e+01\n",
      "  3.88069678e+01  1.46159241e+01 -9.63361061e-01  2.19253276e+00\n",
      "  1.81432548e+01  3.57707914e+01 -2.08144152e+00  7.79780943e+00\n",
      "  3.60392438e+00  1.28140423e+00  4.71161041e+00  3.19419864e+00\n",
      "  1.97427954e-01  8.24020259e+00  3.53213624e+00  1.31227749e+01\n",
      "  1.44510196e+01  7.23295605e+00  1.42019324e+01  1.79437627e+01\n",
      "  2.24287601e+01  2.39059047e+01  1.59310364e+01  1.25347583e+01\n",
      "  2.14270416e+01  1.28157758e+01  3.45197684e+01  9.79815331e+00\n",
      "  3.23372639e+00  7.84237642e+00  2.62874194e+00  4.36231596e+00\n",
      " -4.03759632e+00  2.08904427e+01 -8.32002495e+00  1.86273716e+01\n",
      "  9.83975643e+00  1.75641723e+01  6.66549749e+00  8.81649321e+00\n",
      "  1.27934583e+00  7.57266393e+00 -8.36642565e-01  1.03173435e+01\n",
      " -1.44067886e+00  2.43266292e+00 -2.33291101e-01  3.98171793e+00\n",
      "  4.32798391e+00  8.46900520e+00  1.12342401e+00 -3.30603065e-01\n",
      "  2.20310275e+00  1.83742354e+01  8.95508258e+00  1.85356823e+00\n",
      "  1.86815329e+01  1.74458106e+01  1.69688202e+01 -7.78734319e-01\n",
      "  1.50628539e+00  8.92463749e+00  1.27133072e+01  2.42816013e+01\n",
      "  2.72913330e+01  5.93958068e+00  7.51372541e+00  5.15519395e+00\n",
      "  1.98733657e+01  2.03937679e+00  6.13911736e+00  9.92489681e+00\n",
      "  8.45018879e+00  2.36447681e-02  1.66793070e+01  7.27401714e+00\n",
      "  1.90450314e+01  2.55203353e+00  9.65893459e+00  7.27205855e+00\n",
      "  7.40690151e+00  7.45808166e+00  3.57336306e+00  1.74877036e+01\n",
      "  9.17354797e+00 -1.74633895e+00  3.70742152e+00  1.51397930e+01\n",
      "  2.61653434e+00  2.70234413e+01  1.79194053e+01  4.56486537e+00\n",
      "  2.39357319e+00 -1.02465148e+00  4.66391088e+00  1.11619920e+01\n",
      "  2.96626699e+00  1.37646107e+01  1.96934546e+01  8.07603905e+00\n",
      "  1.21418269e+01  1.36967253e+01  9.98595431e+00  2.21271685e+01\n",
      "  4.18419335e+00  3.05358350e+01  2.59809576e+01  2.42473928e+01\n",
      "  4.17621171e-01  1.12037248e+01  2.13246993e+00 -1.41425207e+00\n",
      "  3.95153338e+00  1.45902930e+01  1.71969501e+01  5.36882716e+00\n",
      "  1.41621985e+01  7.35827183e-01  5.66754459e+00  1.97374642e+01\n",
      "  1.00284699e-01  1.30613084e+01 -8.55820928e-01  1.20751069e+01\n",
      "  2.42650001e+01  8.51591812e+00 -1.24634200e+00  6.66863032e+00\n",
      "  3.69360435e+00  1.65455337e+01  1.96340983e+01  1.01749352e+01\n",
      "  1.53143285e+01  3.17249715e+00  1.03861985e+01  8.24414629e+00\n",
      "  3.85049864e-01  3.96246746e+00  1.87478087e+01  3.14347476e+01\n",
      "  6.00369230e+00  3.51286615e+01  1.91157151e+01  1.89766889e+01\n",
      "  1.28124537e+01  1.88765686e+01  1.17489977e+01  1.17423462e+01\n",
      "  1.26166317e+01  3.82496743e+00  5.03906416e+00  2.48259004e+00\n",
      "  9.33632252e+00  2.25264008e+01  9.22117235e+00  1.88040124e+01\n",
      "  7.11043161e+00  1.24946566e+01  2.27817438e+01  6.12094419e+00\n",
      "  1.56903061e+01  1.22372450e+01  1.11153650e+01  1.33884088e+01\n",
      "  5.63323829e+00  3.38058478e+00  1.92599377e+01  1.92869339e+01\n",
      "  7.15545443e+00  1.38698230e+01  1.22365572e+01  3.21048831e+00\n",
      "  8.93185650e-01  5.47790154e-01  1.28456976e+01  2.46013456e+01\n",
      "  8.26119340e+00  6.49950682e+00  2.53078150e+00  3.79009059e+00\n",
      "  5.26020146e+00 -1.38562033e+00  5.14783979e+00  2.47042329e+00\n",
      "  7.45530875e+00  1.15105305e+01  1.67821725e+01  5.72043925e+00\n",
      "  1.83038518e+01  4.05883123e-01  3.85461231e+00  1.54078318e+01\n",
      " -7.20548323e-01  4.69274320e+00  1.96843510e+00  1.27692313e+01\n",
      "  1.20005796e+01  5.13500985e+00 -6.18624607e-01  9.48820465e+00\n",
      "  8.56768376e+00  5.56083543e+00  1.53307518e+01  5.86147378e+00\n",
      "  1.88197709e+01  4.06468156e+00  1.20019137e+01  5.81506285e+00\n",
      "  1.11250929e+01  6.19492379e+00  1.13545355e+01  1.01168652e+01\n",
      "  3.28505754e+01  4.19070574e+00  4.14157645e+01  7.43192870e+00\n",
      " -5.36004940e-01  1.09340381e+01  4.85296433e+00  1.32250342e+01\n",
      "  6.06214650e+00 -2.16795089e+00  2.22893803e+01  1.02354386e+01\n",
      "  9.73482862e+00  1.62919518e+01  1.72479076e+01  3.64761870e+00\n",
      "  1.23068563e+01  1.55553532e+01  3.12519750e+00  9.47434836e+00\n",
      "  1.06571881e+01  1.24333696e+01  1.80840243e+01  2.73005970e+00\n",
      "  3.31222297e+00  1.74299129e+01  8.25241476e+00  5.59789742e+00\n",
      "  2.56829019e+00  3.91001183e+00 -5.89637910e+00  2.00210144e+01\n",
      "  1.75640737e+00 -8.11742944e-01  8.09134830e+00  4.05960420e+01\n",
      "  1.34441821e+01  1.88813718e+01  2.40934969e+00  7.74805312e+00\n",
      "  5.86318597e+00  1.25304919e+00  1.44230981e+01  6.16956665e+00\n",
      "  3.19596211e+00 -5.20876426e-01  3.04861399e+01  1.57202756e+01\n",
      "  7.28418947e+00  1.53712581e+01  2.55005468e+01  1.80871312e+00\n",
      "  1.68290446e+00  1.26840353e+01  8.81964932e+00  1.27245857e+01\n",
      "  2.08221187e+01  1.02533117e+01  1.13765445e+01  1.35035806e+01\n",
      "  1.24038155e+01  3.88013330e+00  2.66549708e+01  3.58699719e-01\n",
      "  4.96127448e-01  3.12763239e+00  7.78410592e+00  1.17128681e+01\n",
      "  1.98593431e+01  9.81159584e+00  3.54675615e+00  3.05218293e+01\n",
      "  9.20636782e+00 -2.99576762e+00  1.28956294e+01  9.60331468e+00\n",
      "  1.71359200e+00  1.86162075e+01  9.34649898e+00  5.11580586e+00\n",
      "  1.11261308e+01  1.12724823e+01  2.24705062e+01  1.17135053e+01\n",
      "  3.29701432e+00  1.15899832e+01  2.64780326e+00  3.13705120e+00\n",
      "  6.37800249e+00  5.83766849e+00  4.10653015e+00  9.76250136e+00\n",
      "  6.53198914e+00  1.59579818e+01  1.10833319e+01  1.24408167e+01\n",
      "  2.02496119e+00  8.14298572e+00  3.20674748e+00  1.57910666e+01\n",
      "  3.82408183e-01  5.51726026e+00  1.26911111e+01  1.28061578e+01\n",
      "  1.49631764e+01  1.72147221e+01  1.32022732e+01  1.25259870e+01\n",
      "  1.59319701e+01  2.29456117e+01  1.91001469e+01  2.86965334e+01\n",
      "  1.39924683e+01  1.47263507e+01  1.19350166e+00  1.96650748e+01\n",
      "  1.62037674e+01  1.17770164e+01  2.73510209e+01  1.33246410e+01\n",
      " -1.45570824e+00  3.21111092e+00  3.39706703e+00  1.27770638e+01\n",
      "  6.84038729e+00  1.50569026e+01  9.37757134e+00  1.10966417e+01\n",
      "  2.48433955e+01  5.72552919e+00  1.58663636e+01  3.00253701e+00\n",
      "  3.03147729e+00  3.08105308e-01  1.50646642e+00  2.22169017e+01\n",
      "  1.45019981e+00  1.81660807e+01  3.25106040e+01  7.36619248e+00\n",
      "  1.20802356e+01  2.44813427e+01  1.36341249e+01  1.05719240e+01\n",
      "  1.89101603e+01  6.94306190e+00  2.25103115e+01  9.04365970e+00\n",
      "  1.99214294e+01  2.35253746e+01  1.01911186e+01  1.50886126e+01\n",
      "  1.47835786e+01  4.69101325e+01  5.30019494e+00  1.88023859e+01\n",
      "  1.39339831e+01  9.13088798e+00  8.41957494e+00  5.92440831e+00\n",
      "  1.20125778e+01  2.29457736e+01  7.13284601e+00  3.42810837e+00\n",
      "  1.91721772e+01  1.64296212e+00  1.21640155e+01  1.53061286e+01\n",
      "  8.37632588e+00  3.84186613e+00 -1.27384106e+00  1.82252207e+01\n",
      "  4.75778512e+00  1.21621093e+01 -2.52077489e-01  1.22192870e+01\n",
      "  1.08716745e+01  3.71576737e+00  9.05208837e+00 -7.57285976e-01\n",
      "  9.41657462e+00  9.06557637e-01  1.69401705e+00  8.77753567e+00\n",
      " -2.74978515e+00  1.68131988e+01  4.24661948e-01  2.18835974e+01\n",
      "  6.40553192e+00  1.56143473e+01  1.58359016e+01  9.19930854e-01\n",
      "  3.86318822e+00  2.35269020e+01  3.96772856e+00  1.43180987e+01\n",
      "  1.69914859e+01  6.06623200e-02  6.09187598e+00  1.37462245e+01\n",
      "  1.68775611e+01  9.59831099e+00  5.38989419e+00  1.74061627e+01\n",
      "  2.08393599e+01  2.82360356e+00  5.87647836e+00  5.44599137e+01\n",
      "  6.01830303e+00  2.16721933e+01  6.18234677e+00  2.17847389e+01\n",
      " -1.05830672e+00  1.60207795e+01  5.50821531e+00  9.04985402e+00\n",
      "  1.54395795e+01  1.84851619e+01  2.41029145e+00 -9.57948198e-01\n",
      "  8.04254748e+00  1.02771446e+01  2.40110774e+00  2.24500290e+00\n",
      " -3.66003665e-01  1.77388711e+01  1.39330409e+01  3.09737247e+01\n",
      " -2.24337598e-01 -1.80799290e+00 -9.49026632e-02  1.05990659e+01\n",
      "  2.37744668e+01  1.93337499e+00  1.16829225e+01  6.87544981e+00\n",
      "  1.37229501e+01  1.00960582e+01  6.78283392e+00  4.90392344e+00\n",
      "  2.52605103e+01  1.72190155e+01  1.53478308e+01  5.35212001e+00\n",
      "  2.86834258e+01  2.29330198e+01  1.23319413e+01  1.46378788e+01\n",
      "  2.14181826e+01  9.47517921e+00  9.51845786e+00  2.32820255e+01\n",
      " -2.74672913e+00  2.47480441e+00  1.71520223e+00  2.85415082e+01\n",
      "  1.68175656e-01  1.26799735e+01 -1.25398296e+00  1.11725675e+01\n",
      "  1.72283603e+01  1.80617370e+01 -1.00567452e+00  1.85439085e+01\n",
      "  1.81064521e+01 -8.43475091e-01  1.73226673e+01  1.12055796e+01\n",
      "  2.10526460e-02  1.40365170e+01  1.77721543e+01  8.76593825e+00\n",
      "  4.31334005e+00 -6.98117998e-01  3.55846902e+01  3.52425520e+01\n",
      "  9.44840109e+00  8.44947778e+00  4.01696753e+01  4.11598499e+00\n",
      "  1.34871320e+00  4.29008626e+00  6.51613147e-01  2.55790020e+01\n",
      "  1.81925254e+01  2.79956157e+00  4.84551281e+00  8.74803544e+00\n",
      "  1.65030520e+01 -2.15392424e+00  1.29522484e+01  8.69903119e+00\n",
      "  1.03487669e+01  4.58035962e+00  6.79929008e+00  2.29370227e+00\n",
      "  1.26564299e+01 -1.36693139e+00  4.74477002e+00  3.21073892e+00\n",
      " -2.78071729e+00  7.08761012e+00  5.53106240e+00  1.29791862e+01\n",
      " -1.73291371e+00  1.37136502e+00  1.72877682e+01  1.08741449e+01\n",
      "  3.01836184e+00  6.46657260e+00  6.31272848e+00  4.46124615e+00\n",
      " -3.37561679e+00  5.80773330e+00  1.39129873e+01  8.13987554e-01\n",
      "  2.78802368e+01  2.56914662e+00  6.43571826e-01  7.27839959e+00\n",
      "  1.32721709e+01  7.11077499e+00  1.32477179e+01  1.91697999e+01\n",
      "  1.40403552e+01 -8.59129569e-01  8.18692859e+00  6.47053819e+00\n",
      "  4.40862761e+00  1.63931828e+01  1.55404862e+01  1.37984885e+00\n",
      " -2.45160852e+00 -8.71333968e-01  1.07523784e+01  2.77910539e+00\n",
      "  1.68941360e+00  1.11764507e+01  1.54274233e+00  3.68693292e+01\n",
      "  7.40427932e+00  2.25572920e+01  7.76065737e+00  1.63721480e+01\n",
      "  7.13931663e+00  4.68468418e+00  2.33233962e+01  3.85745810e+00\n",
      "  7.28593569e+00  9.35514348e+00  1.48626870e+01  2.23963894e+00\n",
      "  1.05932667e+01  5.65094350e+00  1.92962120e+01  1.55317660e+01\n",
      "  7.02843637e+00  1.03697369e+01  1.69717990e+01  6.90426368e+00\n",
      "  1.22355780e+01  1.13674700e+01  1.63118243e+01  2.41561671e+01\n",
      "  4.22667665e+01  2.39319079e+00  4.46067094e-01  2.87950682e+01\n",
      "  3.98897880e+00  2.10344606e+01  1.25903944e+01  5.29565284e+00\n",
      "  9.37675515e+00  1.62165656e+01  7.25680109e+00  4.48175484e+00\n",
      "  4.55237655e+00  1.30113493e+01  1.25061703e+01  3.58770499e+00\n",
      "  2.44427166e-01  1.06774188e+00  9.80252870e+00  4.09409268e+00\n",
      "  2.37858284e+01  1.75906374e+01  9.49131795e+00  4.17796151e+00\n",
      "  1.15558421e+01  1.95764387e+01 -9.74740421e-01  2.27342161e+01\n",
      "  1.40133136e+01  5.81299861e+00  2.26719262e+01  1.17963271e+01\n",
      "  2.64105950e+00  7.38010831e+00 -8.20887218e-01  1.35667279e+01\n",
      "  1.67902391e+01  1.72448940e+01  6.49917989e+00  2.09973362e+01\n",
      "  7.71654170e+00  2.58726296e+01  8.71037871e+00 -5.30038961e-01\n",
      "  1.49516927e+01  7.95287605e+00  2.32580067e+01  1.88839094e+01\n",
      "  1.75432128e+01  2.00729360e-01  1.68037914e+01  1.19621757e+01\n",
      "  8.06655902e+00  9.33042015e+00  2.17858438e+01  1.84822318e+01\n",
      "  2.64481861e+01  1.65409829e+01  1.20875604e+01  4.01521789e+00\n",
      " -6.83508462e+00  1.90263178e+01  1.34460653e+01  2.63292635e+01\n",
      "  1.45104513e+01  2.05200718e+00  6.94067080e+00  5.45906498e-01\n",
      "  3.65871508e+00  1.02682694e+01  1.29364455e+01  2.43032911e+01\n",
      "  7.70967956e+00  2.62077800e+00  1.45574214e+01  1.16773991e+01\n",
      "  7.45695130e+00  1.30630701e+01  2.05901005e+00  4.57409119e+00\n",
      "  7.42017275e+00 -1.07359504e+00  8.27277697e+00  3.65057515e+01\n",
      "  3.39514274e+01  2.06565501e+00  7.30337925e+00  5.63607240e+00\n",
      "  8.33573916e+00  4.39160999e+00  7.51827913e+00  8.22091937e+00\n",
      "  2.35628688e+00  7.77046787e+00  1.11829662e+01  1.49257015e+01\n",
      "  1.44721745e+01  1.82248272e+01  1.50145137e+01  2.69396906e+01\n",
      "  2.20131983e+01  1.22548727e+01  1.06033720e+01  1.49738887e+01\n",
      "  5.20771290e+00  7.23318067e+00  1.25251411e+01  8.01331863e+00\n",
      "  1.28562937e+01  8.77951616e-01  2.09661971e+01 -1.17395532e+00\n",
      "  6.53949641e+00  1.38523444e+01 -1.09160974e+00  1.20882074e+01\n",
      "  8.01489184e+00 -2.01819160e+00  1.25489084e+01 -5.03284889e-01\n",
      "  7.82879031e+00  2.19891046e+00  1.71882789e+01  3.82640992e+00\n",
      "  6.02293538e+00  2.39967610e+01  1.19534846e+00  5.69993201e-01\n",
      "  1.89626268e+01  1.52331221e+00  2.84259596e+00  6.02367486e+00\n",
      "  4.08838214e+00  2.54805688e+01  2.56513863e+00  1.92802467e+01\n",
      "  1.81259933e+01  3.69866043e+00  1.52227573e+01  1.63909240e+01\n",
      "  5.62445778e+00  2.86624678e+01  1.32101903e+00  1.79567458e+01\n",
      "  1.55212477e+01  4.98143977e+00  2.00362645e+00  6.87602805e+00\n",
      "  4.53983352e+00  3.15702634e+00  1.52942370e+01  5.18529862e+00\n",
      "  4.05039021e+00  1.45454801e+01  5.32533696e+00  1.32472469e+01\n",
      "  6.55274462e+00  8.84821310e+00  6.80691308e+00  2.31852322e+01\n",
      "  1.63747170e+01  3.82281376e+00  1.34524724e+01  1.01120478e+01\n",
      "  3.84877102e+01  1.90190193e+01  1.14162890e+01 -5.36046974e-01\n",
      "  1.08999502e+01  6.34931058e+00  2.00921435e+01  4.37176680e+00\n",
      "  1.87614171e+01  1.27745213e+00  1.19366506e+01  2.64506824e+01\n",
      "  1.69300130e+01  3.71069421e+00  6.09391750e+00  8.74424612e-01\n",
      "  1.13516330e+01  1.26465853e+01  4.33745497e+00  2.22614010e+01\n",
      "  1.85490256e+01  1.34165210e+01  6.30826473e+00  2.77840039e+00]\n"
     ]
    }
   ],
   "source": [
    "# Add polynomial and bias term with the feature vector using the sklearn PolynomialFeatures class\n",
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_test_poly = poly_features.fit_transform(X_test)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Test Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_test_poly_predicted = lin_reg_ridge.predict(X_test_poly)\n",
    "\n",
    "\n",
    "ridge_test_mse = mean_squared_error(y_test, y_test_poly_predicted)\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\" % ridge_test_mse)\n",
    "\n",
    "\n",
    "\n",
    "ridge_test_r2_score = r2_score(y_test, y_test_poly_predicted)\n",
    "print('Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f' \n",
    "      % ridge_test_r2_score)\n",
    "print(y_test, y_test_poly_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Best Score (negative mean squared error): -27.144329\n",
      "Optimal Hyperparameter Values:  {'alpha': 10.0}\n",
      "\n",
      "\n",
      "Wall time: 263 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "\n",
    "#param_grid = {'alpha': np.linspace(10.0, 20.0, num=10)}\n",
    "param_grid = {'alpha': np.linspace(10,40,num=100)}\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "lasso_cv = GridSearchCV(ridge, param_grid, scoring='neg_mean_squared_error', cv=10, verbose=1, n_jobs=-1)\n",
    "lasso_cv.fit(X_train_poly, y_train)\n",
    "\n",
    "params_optimal_lasso = lasso_cv.best_params_\n",
    "\n",
    "print(\"Best Score (negative mean squared error): %f\" % lasso_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_lasso)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha:  10.0\n",
      "\n",
      "----------------------------- Model Evaluation -----------------------------\n",
      "\n",
      "Mean squared error: 26.87\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "\n",
    "# Optimal model parameters\n",
    "lasso_alpha = lasso_cv.best_params_['alpha']\n",
    "print(\"Optimal alpha: \", lasso_alpha)\n",
    "\n",
    "\n",
    "# Create Lasso linear regression object\n",
    "lin_reg_lasso = Ridge(alpha=lasso_alpha)\n",
    "\n",
    "# Train the model\n",
    "lin_reg_lasso.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_lasso = lin_reg_lasso.predict(X_train_poly)\n",
    "\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_predicted_lasso))\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % r2_score(y_train, y_train_predicted_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------- Test Model Evaluation -----------------------------\n",
      "\n",
      "Mean squared error: 26.79\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Add polynomial and bias term with the feature vector using the sklearn PolynomialFeatures class\n",
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_test_poly = poly_features.fit_transform(X_test)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Test Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_test_poly_predicted = lin_reg_lasso.predict(X_test_poly)\n",
    "\n",
    "lasso_test_mse = mean_squared_error(y_test, y_test_poly_predicted)\n",
    "\n",
    "print(\"\\nMean squared error: %.2f\" % lasso_test_mse)\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "\n",
    "lasso_test_r2_score = r2_score(y_test, y_test_poly_predicted)\n",
    "print('Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f' \n",
    "      % lasso_test_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1152 candidates, totalling 11520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 520 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 9324 tasks      | elapsed:    7.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (negative mean squared error): -26.958092\n",
      "Optimal Hyperparameter Values:  {'alpha': 0.01, 'eta0': 0.001, 'l1_ratio': 0.2, 'learning_rate': 'constant', 'loss': 'squared_loss', 'max_iter': 100}\n",
      "\n",
      "\n",
      "Wall time: 9.66 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 11520 out of 11520 | elapsed:    9.5s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "param_grid = {'alpha': [0.1, 0.01, 0.001], 'learning_rate': [\"constant\", \"optimal\", \"invscaling\"], \n",
    "              'l1_ratio': [1, 0.5, 0.2, 0], 'max_iter':[100, 400, 1000, 10000],'eta0': [0.01, 0.001],\n",
    "              'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']}\n",
    "\n",
    "\n",
    "\n",
    "sgd = SGDRegressor()\n",
    "\n",
    "sgd_cv = GridSearchCV(sgd, param_grid, scoring='neg_mean_squared_error', cv=10, verbose=2, n_jobs=-1)\n",
    "sgd_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "params_optimal_sgd = sgd_cv.best_params_\n",
    "\n",
    "print(\"Best Score (negative mean squared error): %f\" % sgd_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_sgd)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------- Model Evaluation -----------------------------\n",
      "Mean squared error: 27.07\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.73\n"
     ]
    }
   ],
   "source": [
    "# SGD Regression\n",
    "\n",
    "# Create SGDRegressor linear regression object using the optimal hyperparameter values\n",
    "lin_reg_sgd = SGDRegressor(**params_optimal_sgd)\n",
    "\n",
    "# Train the model\n",
    "lin_reg_sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_sgd = lin_reg_sgd.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_predicted_sgd))\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % r2_score(y_train, y_train_predicted_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-26.51134821 -20.90608873 -29.27874878 -28.62805632 -27.12496999\n",
      " -24.86951706 -30.60540362 -32.69012603 -26.85733324 -25.75875203]\n",
      "Negative Mean Squared Error: -27.32 (+/- 6.19)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scoring Parameter for Regression:\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "scores = cross_val_score(lin_reg_sgd, X_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "print(scores)\n",
    "\n",
    "print(\"Negative Mean Squared Error: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 26.90\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.72\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted = lin_reg_sgd.predict(X_test)\n",
    "\n",
    "\n",
    "test_mse_linear = mean_squared_error(y_test, y_test_predicted)\n",
    "\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % test_mse_linear)\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "test_r2_linear = r2_score(y_test, y_test_predicted)\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % test_r2_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Original Features:  10\n",
      "No. of Augmented Features:  65\n"
     ]
    }
   ],
   "source": [
    "# Variable that speficies the degree of the polynomial to be added to the feature vector\n",
    "poly_degree = 2\n",
    "\n",
    "\n",
    "# Add polynomial terms with the feature vector using the sklearn PolynomialFeatures class\n",
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "\n",
    "\n",
    "print(\"No. of Original Features: \", X_train.shape[1])\n",
    "print(\"No. of Augmented Features: \", X_train_poly.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 384 candidates, totalling 3840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1651 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2096 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3717 tasks      | elapsed:   30.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (negative mean squared error): -22.711784\n",
      "Optimal Hyperparameter Values:  {'alpha': 0.01, 'eta0': 0.001, 'l1_ratio': 0, 'learning_rate': 'invscaling', 'loss': 'squared_loss', 'max_iter': 10000}\n",
      "\n",
      "\n",
      "Wall time: 33.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3840 out of 3840 | elapsed:   33.1s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "# param_grid = {'alpha': [0.1, 0.01], 'learning_rate': [\"invscaling\"], \n",
    "#               'l1_ratio': [1, 0.5, 0.2, 0], 'max_iter':[100, 400, 1000, 5000],'eta0': [0.01, 0.001, 0.0001]}\n",
    "\n",
    "\n",
    "param_grid = {'alpha': [0.1, 0.01], 'learning_rate': [\"invscaling\"], \n",
    "              'l1_ratio': [1, 0.5, 0.2, 0], 'max_iter':[100, 400, 1000, 10000],'eta0': [0.01, 0.001, 0.0001],\n",
    "              'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']}\n",
    "\n",
    "\n",
    "\n",
    "sgd = SGDRegressor()\n",
    "\n",
    "sgd_cv = GridSearchCV(sgd, param_grid, scoring='neg_mean_squared_error', cv=10, verbose=2, n_jobs=-1)\n",
    "sgd_cv.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "params_optimal_sgd = sgd_cv.best_params_\n",
    "\n",
    "print(\"Best Score (negative mean squared error): %f\" % sgd_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_sgd)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Iterations: \n",
      " 104\n",
      "\n",
      "----------------------------- Model Evaluation -----------------------------\n",
      "Mean squared error: 20.98\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SGD Regression\n",
    "\n",
    "# Create SGDRegressor linear regression object using the optimal hyperparameter values\n",
    "lin_reg_sgd = SGDRegressor(**params_optimal_sgd)\n",
    "\n",
    "# Train the model\n",
    "lin_reg_sgd.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "# # The intercept\n",
    "# print(\"Intercept: \\n\", lin_reg_sgd.intercept_)\n",
    "\n",
    "# # The coefficients\n",
    "# print(\"Coefficients: \\n\", lin_reg_sgd.coef_)\n",
    "\n",
    "# The number of iterations\n",
    "print(\"Number of Iterations: \\n\", lin_reg_sgd.n_iter_)\n",
    "\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_sgd = lin_reg_sgd.predict(X_train_poly)\n",
    "\n",
    "\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_predicted_sgd))\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % r2_score(y_train, y_train_predicted_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 33.44\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.66\n"
     ]
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "X_test_poly = poly_features.fit_transform(X_test)\n",
    "\n",
    "# Make prediction using the test data\n",
    "y_test_predicted = lin_reg_sgd.predict(X_test_poly)\n",
    "\n",
    "test_mse_polynomial = mean_squared_error(y_test, y_test_predicted)\n",
    "\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % test_mse_polynomial)\n",
    "\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "\n",
    "test_r2_polynomial = r2_score(y_test, y_test_predicted)\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % test_r2_polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>SGD Linear Regression</th>\n",
       "      <th>SGD Polynomial Regression (degree 2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE (test)</td>\n",
       "      <td>26.904468</td>\n",
       "      <td>33.439153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R2 Score (test)</td>\n",
       "      <td>0.722664</td>\n",
       "      <td>0.655304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metric  SGD Linear Regression  \\\n",
       "0       MSE (test)              26.904468   \n",
       "1  R2 Score (test)               0.722664   \n",
       "\n",
       "   SGD Polynomial Regression (degree 2)  \n",
       "0                             33.439153  \n",
       "1                              0.655304  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[\"MSE (test)\", test_mse_linear, test_mse_polynomial], \n",
    "        [\"R2 Score (test)\", test_r2_linear, test_r2_polynomial]]\n",
    "pd.DataFrame(data, columns=[\"Metric\", \"SGD Linear Regression\", \"SGD Polynomial Regression (degree 2)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create CV training and validation scores for various training set sizes\n",
    "train_sizes, train_scores, val_scores = learning_curve(Ridge(alpha=0.94, solver='sparse_cg'), X_train_poly, y_train, cv=5, \n",
    "                                                        scoring='neg_mean_squared_error', \n",
    "                                                        train_sizes=np.linspace(0.01, 1.0, 50),\n",
    "                                                        n_jobs=-1)\n",
    "                                                \n",
    "                                                                                                                                                                                                                 \n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of validation set scores\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, \"r-+\", linewidth=3, label=\"Training Score\")\n",
    "plt.plot(train_sizes, val_mean, \"b-\", linewidth=2, label=\"Cross-validation Score\")\n",
    "plt.legend(loc=\"best\", fontsize=14)   \n",
    "plt.xlabel(\"Training set size\", fontsize=14) \n",
    "plt.ylabel(\"Negative MSE\", fontsize=14) \n",
    "plt.title(\"Learning Curve (Linear Model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High bias problem More advanced model needed \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM(RBF kernel) and Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (negative mean squared error): -21.186922\n",
      "Optimal Hyperparameter Values:  {'C': 100, 'gamma': 0.001}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'gamma': [0.000001, 0.0001, 0.001, 0.01, 0.1, 1], \n",
    "              'C': [10, 100, 1000, 10000]}\n",
    "\n",
    "\n",
    "\n",
    "svm = SVR(kernel=\"rbf\")\n",
    "\n",
    "svm_cv = GridSearchCV(svm, param_grid, scoring='neg_mean_squared_error', cv=10, verbose=2, n_jobs=-1)\n",
    "svm_cv.fit(X, y)\n",
    "\n",
    "\n",
    "params_optimal = svm_cv.best_params_\n",
    "\n",
    "print(\"Best Score (negative mean squared error): %f\" % svm_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------- Model Evaluation -----------------------------\n",
      "Train: Mean squared error: 25.21\n",
      "Train: Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.75\n",
      "\n",
      "Test: Mean squared error: 25.76\n",
      "Test: Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.73\n"
     ]
    }
   ],
   "source": [
    "svm = SVR(kernel=\"rbf\", **params_optimal)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n----------------------------- Model Evaluation -----------------------------\")\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_svm = svm.predict(X_train)\n",
    "\n",
    "\n",
    "print(\"Train: Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_predicted_svm))\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Train: Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" % r2_score(y_train, y_train_predicted_svm))\n",
    "\n",
    "\n",
    "# Make prediction using the test data\n",
    "y_test_predicted_svm = svm.predict(X_test)\n",
    "\n",
    "test_mse_svm = mean_squared_error(y_test, y_test_predicted_svm)\n",
    "\n",
    "print(\"\\nTest: Mean squared error: %.2f\"\n",
    "      % test_mse_svm)\n",
    "\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "\n",
    "test_r2_svm = r2_score(y_test, y_test_predicted_svm)\n",
    "print(\"Test: Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % test_r2_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (accuracy): -21.063908\n",
      "Optimal Hyperparameter Values:  {'max_depth': 110, 'max_features': 'sqrt', 'n_estimators': 600}\n",
      "\n",
      "\n",
      "Wall time: 11min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rnd_forest_reg = RandomForestRegressor()\n",
    "\n",
    "dt_clf_cv = GridSearchCV(rnd_forest_reg, param_grid, scoring='neg_mean_squared_error', cv=5, verbose=2, n_jobs=-1)\n",
    "dt_clf_cv.fit(X_train, y_train)\n",
    "\n",
    "params_optimal = dt_clf_cv.best_params_\n",
    "\n",
    "print(\"Best Score (accuracy): %f\" % dt_clf_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    " params_optimal = {'max_depth': 10, 'max_features': 'auto', 'n_estimators': 1800}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1800 out of 1800 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 1800 out of 1800 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Mean squared error: 7.33\n",
      "Train: Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.93\n",
      "Test: Mean squared error: 23.21\n",
      "Test: Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 1800 out of 1800 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "rnd_forest_reg = RandomForestRegressor(**params_optimal,criterion=\"mse\"\n",
    "                                       ,verbose=1,\n",
    "                                       oob_score=True, n_jobs=-1)\n",
    "\n",
    "rnd_forest_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_rnd_forest = rnd_forest_reg.predict(X_train)\n",
    "\n",
    "\n",
    "train_mse_rnd_forest = mean_squared_error(y_train, y_train_predicted_rnd_forest)\n",
    "\n",
    "print(\"Train: Mean squared error: %.2f\"\n",
    "      % train_mse_rnd_forest)\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Train: Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % r2_score(y_train, y_train_predicted_rnd_forest))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_test_predicted_rnd_forest = rnd_forest_reg.predict(X_test)\n",
    "\n",
    "\n",
    "test_mse_rnd_forest = mean_squared_error(y_test, y_test_predicted_rnd_forest)\n",
    "\n",
    "print(\"Test: Mean squared error: %.2f\"\n",
    "      % test_mse_rnd_forest)\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "\n",
    "test_r2_rnd_forest = r2_score(y_test, y_test_predicted_rnd_forest)\n",
    "\n",
    "\n",
    "print(\"Test: Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % test_r2_rnd_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create CV training and validation scores for various training set sizes\n",
    "train_sizes, train_scores, val_scores = learning_curve(RandomForestRegressor(**params_optimal,criterion=\"mse\"\n",
    "                                       ,verbose=1,\n",
    "                                       oob_score=True, n_jobs=-1), X_train, y_train, cv=5, \n",
    "                                                        scoring='neg_mean_squared_error', \n",
    "                                                        train_sizes=np.linspace(0.01, 1.0, 50),\n",
    "                                                        n_jobs=-1)\n",
    "                                                \n",
    "                                                                                                                                                                                                                 \n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of validation set scores\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, \"r-+\", linewidth=3, label=\"Training Score\")\n",
    "plt.plot(train_sizes, val_mean, \"b-\", linewidth=2, label=\"Cross-validation Score\")\n",
    "plt.legend(loc=\"best\", fontsize=14)   \n",
    "plt.xlabel(\"Training set size\", fontsize=14) \n",
    "plt.ylabel(\"Negative MSE\", fontsize=14) \n",
    "plt.title(\"Learning Curve (Linear Model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need More DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1800 out of 1800 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 1800 out of 1800 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Mean squared error: 7.36\n",
      "Train: Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.93\n",
      "Test: Mean squared error: 23.17\n",
      "Test: Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 1800 out of 1800 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "rnd_forest_reg = RandomForestRegressor(**params_optimal,criterion=\"mse\"\n",
    "                                       ,verbose=1,\n",
    "                                       oob_score=True, n_jobs=-1)\n",
    "\n",
    "rnd_forest_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_rnd_forest = rnd_forest_reg.predict(X_train)\n",
    "\n",
    "\n",
    "train_mse_rnd_forest = mean_squared_error(y_train, y_train_predicted_rnd_forest)\n",
    "\n",
    "print(\"Train: Mean squared error: %.2f\"\n",
    "      % train_mse_rnd_forest)\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Train: Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % r2_score(y_train, y_train_predicted_rnd_forest))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_test_predicted_rnd_forest = rnd_forest_reg.predict(X_test)\n",
    "\n",
    "\n",
    "test_mse_rnd_forest = mean_squared_error(y_test, y_test_predicted_rnd_forest)\n",
    "\n",
    "print(\"Test: Mean squared error: %.2f\"\n",
    "      % test_mse_rnd_forest)\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "\n",
    "test_r2_rnd_forest = r2_score(y_test, y_test_predicted_rnd_forest)\n",
    "\n",
    "\n",
    "print(\"Test: Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % test_r2_rnd_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  1, 38,  1,  7, 29, 15, 18, 26,  2,  7, 12,  7, 46,  8, 26,  4,\n",
       "        1,  5, 12,  6,  2, 16,  9,  7,  3, 23,  6, 15, 24,  4,  2, 18, 52,\n",
       "        3, 20, 17,  2, 13, 10,  0,  9, 34,  6,  4,  0,  4,  3,  5, 11,  3,\n",
       "       22,  2,  2, 19,  6,  1, 14, 17, 17,  6,  0,  6, 15, 17,  1,  6,  5,\n",
       "       11, 18, 17, 34, 49, 10,  1,  3, 17, 52,  3,  2,  5,  1,  1,  5,  0,\n",
       "        6,  5, 17, 16,  4, 25, 19, 18, 29, 19,  9, 24,  7, 41, 11,  3,  2,\n",
       "        4,  3,  2, 18,  3, 24,  3, 14,  8, 13,  1,  9,  7, 15,  2,  6,  1,\n",
       "        3,  6, 11,  9,  1,  2, 18, 10,  1, 23,  1, 17,  1,  0,  7, 12, 21,\n",
       "       34, 11, 20,  3, 14,  1, 10,  4,  8,  3, 21,  3, 31,  0, 11, 12,  9,\n",
       "        5,  4, 19,  9,  0,  1,  2,  3, 25, 13,  2, 13,  0,  3,  4,  3, 19,\n",
       "       20,  7, 19, 11,  7, 22,  0, 45, 23, 16,  0,  8,  3,  7,  6, 21, 20,\n",
       "        0, 12,  2,  4, 24,  2, 13,  2, 14, 28,  4,  3,  6,  3, 15, 19, 13,\n",
       "       15,  1,  7,  7,  2,  1,  1, 20,  6, 48, 15, 16,  7, 17, 20, 17, 14,\n",
       "        4, 10,  1,  6, 15,  9, 33,  9,  5, 21,  5, 17, 18, 14, 15,  2,  0,\n",
       "       20, 17, 12,  7,  9,  1,  4,  9, 15, 13,  7,  6,  2,  6,  5,  0,  1,\n",
       "        1,  7, 16, 21,  1, 23,  8,  2,  6,  3,  2,  7,  9, 13,  0,  4,  6,\n",
       "        6,  5, 17,  1, 20,  2, 11,  3,  4,  6,  9,  9, 42,  0, 44,  1,  0,\n",
       "       15,  4,  7, 21,  0, 24,  8,  9,  9, 15,  4,  8,  8,  1, 12,  7,  5,\n",
       "       21,  1,  2, 11,  7,  3,  1,  4,  1, 18,  2,  0,  5, 44, 11, 17,  0,\n",
       "        5,  4,  3,  7, 10,  6,  4, 36, 20, 12, 19, 25,  2,  4,  9, 10, 12,\n",
       "       13, 14, 11,  8,  3,  7, 20,  4,  1,  2,  2,  9, 18,  4,  4, 30, 26,\n",
       "        1, 19, 10,  1, 23,  5,  1,  8,  9, 20,  8,  3,  5,  1,  4, 10,  4,\n",
       "        3,  8,  8, 10, 14, 10, 10,  1,  5,  1,  0,  3, 14, 13,  4, 22,  9,\n",
       "       15, 12, 18, 38, 34, 17,  9,  4, 15, 21, 16, 30, 10,  1,  2,  3,  4,\n",
       "        5, 14,  9, 14, 17,  4, 13,  2,  3,  2,  0, 17,  1, 11, 27,  3,  8,\n",
       "       25,  4,  9, 13,  5,  6,  2, 16, 22, 11, 22,  9, 53,  5, 27, 19,  5,\n",
       "        1, 10, 16, 23,  3,  2, 16,  3,  6, 18,  3,  2,  2,  9,  5, 10,  0,\n",
       "       15,  8,  6,  5,  1,  7,  5,  3, 10,  3, 18,  0, 20,  3, 12, 16,  4,\n",
       "        1, 30,  4,  7,  8,  3,  9, 13, 17,  7,  3, 27,  7,  5,  7,  0,  0,\n",
       "       29,  9, 17,  2, 21, 10,  3, 13, 16,  1,  4,  8, 16,  1,  3,  2, 16,\n",
       "       14, 37,  1,  0,  5,  9, 23,  3, 15,  3,  5,  9, 10,  3, 31, 17,  9,\n",
       "        4, 35, 26, 15, 23, 17,  7,  5, 26,  2,  3,  1, 24,  2, 16,  2, 17,\n",
       "       14, 17,  4, 24, 22,  2, 16, 13,  2, 19, 17, 10,  7,  0, 50, 49,  6,\n",
       "       12, 49,  4,  2,  3,  1, 13, 16,  1,  2,  5, 15,  2, 17,  2, 15, 10,\n",
       "        9,  0,  8,  1,  4,  2,  2,  5, 11, 11,  1,  2, 17, 17,  1, 15,  3,\n",
       "        1,  1,  0, 22,  2, 37,  1,  3,  9, 10,  9,  5, 19, 12,  2, 11,  4,\n",
       "        6, 18, 17,  1,  3,  4,  6,  0,  2, 12,  0, 46,  6, 21,  9, 18,  5,\n",
       "        8, 35,  1,  6, 10, 16,  1,  5,  6, 18, 16,  2, 12, 13,  0, 16,  0,\n",
       "       15, 21, 55,  1,  0, 19,  1, 27, 15,  7, 11, 12,  3,  1,  1,  9,  6,\n",
       "        4,  6,  3, 12,  2, 14, 13,  6, 14, 10, 11,  1, 34, 10,  2, 20, 16,\n",
       "        3,  7,  0, 10, 11, 18,  3, 16,  7, 29, 12,  1,  9,  5, 30, 27, 21,\n",
       "        2, 18, 10,  6,  6, 20, 16, 19, 16, 10,  4,  3, 17, 25, 19, 16,  5,\n",
       "       21,  3,  2,  6, 10, 29,  4,  2, 12,  6,  0, 11,  5,  3,  2,  0,  5,\n",
       "       51, 33,  0,  5,  3,  5,  4,  9,  9,  3,  5,  6, 17, 10, 17, 16, 25,\n",
       "       18,  8,  8, 17,  3, 22,  7,  6, 14,  2, 20,  1,  8, 15,  3,  5,  7,\n",
       "        2,  4,  0,  2,  3, 18,  6,  3, 17,  1,  0, 17,  4,  1,  5,  2, 28,\n",
       "        3,  8, 34, 10, 21, 30,  1, 31,  4, 13,  9,  2,  6, 10,  4,  2, 16,\n",
       "        4,  6, 10,  9, 16,  7,  1,  8, 25, 14,  1, 17, 11, 52, 20,  6,  3,\n",
       "       12,  9, 28,  7, 16,  3, 11, 23, 16,  2,  4,  3,  9,  8,  5,  9, 16,\n",
       "       11,  2,  4], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  1, 24,  3,  5, 17, 13,  7, 13,  7, 12, 10,  5, 45, 10, 16,  6,\n",
       "        6,  5, 10, 10,  6, 16,  7,  4,  3, 18,  9,  9, 20,  9,  5, 15, 53,\n",
       "        3, 17, 17,  4, 14, 11,  1,  7, 14,  8,  2,  3,  4,  7,  5,  3,  2,\n",
       "       16,  3,  5, 16, 10,  2, 17, 16,  9,  7,  2, 10, 16, 16,  2,  4,  3,\n",
       "       10, 15, 18, 29, 45,  9,  2,  4, 17, 39,  2,  5,  5,  2,  3,  4,  2,\n",
       "        9,  2, 16, 16,  7, 17, 15, 18, 27, 12, 10, 18,  9, 52, 11,  5,  5,\n",
       "        4,  2,  1, 16,  1, 11, 10, 16,  8,  6,  2,  8,  1, 13,  2,  4,  1,\n",
       "        4,  4,  6,  3,  2,  2, 16,  8,  3, 17, 13, 17,  1,  2, 11,  8, 20,\n",
       "       29,  5, 10,  3, 17,  1,  7, 13,  6,  2, 16,  7, 16,  4, 11,  8,  6,\n",
       "        7,  1, 17,  8,  1,  2, 13,  1, 32, 16,  5,  3,  1,  6,  9,  5, 11,\n",
       "       17, 11, 14, 14,  8, 19,  1, 44, 33, 21,  2, 12,  3,  2,  5, 16, 16,\n",
       "        3, 13,  2,  3, 18,  2,  9,  2, 12, 19,  7,  2,  4,  2, 13, 16,  9,\n",
       "       13,  3,  9,  8,  1,  5, 22, 26,  5, 43, 16, 17, 13, 17, 12, 11, 13,\n",
       "        2,  5,  3,  5, 17, 10, 16,  4, 10, 18,  7, 17, 11,  9, 12,  3,  2,\n",
       "       16, 16,  5, 12, 15,  2,  2,  2, 14, 17,  7,  6,  3,  2,  4,  1,  4,\n",
       "        3,  4, 13, 16,  8, 17,  3,  5, 16,  1,  2,  7,  9, 11,  4,  3, 10,\n",
       "        8,  4, 16,  3, 16,  4,  7,  2,  9,  5, 11, 11, 39,  5, 53,  6,  1,\n",
       "       13,  3, 11,  5,  3, 17,  8, 10, 15, 22,  3, 11, 13,  3,  7,  9, 12,\n",
       "       18,  2,  5, 15, 10,  6,  3,  3,  2, 17,  2,  2,  5, 50, 15, 16,  2,\n",
       "        7,  5,  2, 14,  8,  3,  1, 26, 15,  4, 13, 27,  2,  2, 10,  5, 13,\n",
       "       22,  9,  9, 16, 12,  2, 21,  2,  2,  2,  6, 10, 16,  7,  4, 42, 10,\n",
       "        1,  9, 10,  2, 17,  9,  3, 10, 12, 17, 11,  5,  9,  2,  2,  6,  5,\n",
       "        3,  9,  8, 12, 11,  9,  3,  4,  3,  6,  2,  3, 13, 12, 11, 14, 11,\n",
       "       10, 15, 18,  9, 39, 11, 14,  2, 17, 11, 15, 24, 13,  2,  3,  2, 13,\n",
       "        6, 15,  9,  6, 28,  5, 14,  4,  2,  3,  5, 17,  2, 17, 41,  9, 12,\n",
       "       19,  9, 13, 17,  7, 16,  6, 18, 21, 10, 13, 13, 56,  4, 17, 16,  8,\n",
       "       10,  5, 15, 19,  7,  4, 17,  3, 10, 15,  5,  1,  4, 14,  3, 10,  2,\n",
       "       10,  8,  6,  8,  2,  9,  2,  3,  9,  2, 15,  1, 18,  6, 15, 16,  3,\n",
       "        1, 35,  3, 16, 15,  2,  6, 10, 16,  9,  2, 16, 17,  3,  5, 50,  4,\n",
       "       19,  9, 18,  3, 16,  6,  6,  9, 16,  3,  2,  8, 10,  2,  2,  2, 16,\n",
       "       15, 31,  2,  1,  2, 10, 19,  2,  9,  4, 13, 10, 11,  3, 17, 16, 13,\n",
       "        4, 27, 29, 16, 14, 17,  8,  8, 24,  1,  4,  1, 27,  1, 12,  2, 12,\n",
       "       14, 17,  1, 16, 17,  2, 20, 11,  2,  8, 17,  7,  6,  2, 50, 47,  8,\n",
       "       10, 43,  3,  2,  2,  2, 20, 16,  2,  4,  8, 16,  2, 12,  9, 11,  3,\n",
       "        5,  3, 11,  2,  6,  2,  1,  6,  4, 12,  1,  2, 15, 19,  4,  7,  5,\n",
       "        6,  1,  4, 13,  1, 37,  3,  2,  8, 12,  8,  7, 17, 14,  1, 12,  5,\n",
       "        2, 16, 16,  2,  1,  2, 11,  1,  2, 11,  1, 48,  4, 18,  7, 16,  4,\n",
       "        7, 32,  4,  5, 10, 16,  3,  9,  6, 16, 12,  5,  8, 16,  5, 13,  9,\n",
       "       16, 18, 57,  1,  1, 22,  1, 18, 11,  4, 10, 15,  8,  2,  2, 15,  9,\n",
       "        5,  2,  1, 11,  3, 19, 15, 10,  2, 12, 16,  2, 23, 14,  5, 18, 11,\n",
       "        3,  3,  1, 10, 16, 16,  4, 17,  9, 23,  8,  1, 16,  9, 28, 17, 16,\n",
       "        2, 16,  9,  4,  7, 20, 14, 17, 16, 12,  2,  2, 17, 15, 18, 15,  2,\n",
       "        8,  2,  4,  9, 13, 23,  6,  3, 16,  9,  7, 14,  4,  5,  5,  1,  8,\n",
       "       37, 33,  1, 10,  6,  9,  3,  8,  7,  4,  8,  7, 14, 14, 22, 16, 29,\n",
       "       17, 10,  6, 12,  2,  5,  8,  9, 13,  1, 17,  1,  3, 13,  1,  8,  9,\n",
       "        2,  9,  3,  4,  3, 16,  4,  5, 17,  1,  2, 15,  2,  2,  3,  2, 21,\n",
       "        1, 17, 17,  3, 12, 13,  3, 27,  3, 18, 16,  2,  3,  7,  3,  5, 15,\n",
       "        8,  3, 15,  2, 13,  7,  6,  7, 19, 16,  2, 14, 10, 48, 17,  8,  1,\n",
       "        7,  7, 17,  6, 16,  1,  9, 28, 14,  1,  3,  2, 10, 10,  4, 20, 15,\n",
       "       13,  6,  2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted_rnd_forest.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 20, num = 6)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 350 out of 350 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (accuracy): -21.285496\n",
      "Optimal Hyperparameter Values:  {'max_depth': 14, 'max_features': 'auto', 'n_estimators': 800}\n",
      "\n",
      "\n",
      "Wall time: 5min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rnd_forest_reg = RandomForestRegressor()\n",
    "\n",
    "dt_clf_cv = GridSearchCV(rnd_forest_reg, param_grid, scoring='neg_mean_squared_error', cv=5, verbose=2, n_jobs=-1)\n",
    "dt_clf_cv.fit(X, y)\n",
    "\n",
    "params_optimal = dt_clf_cv.best_params_\n",
    "\n",
    "print(\"Best Score (accuracy): %f\" % dt_clf_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = PolynomialFeatures(degree=4, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3344, 1000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 800 out of 800 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Mean squared error: 3.70\n",
      "Train: Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.96\n",
      "Test: Mean squared error: 23.17\n",
      "Test: Coefficient of determination r^2 variance score [1 is perfect prediction]: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 800 out of 800 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "rnd_forest_reg = RandomForestRegressor(**params_optimal,criterion=\"mse\"\n",
    "                                       ,verbose=1,\n",
    "                                       oob_score=True, n_jobs=-1)\n",
    "\n",
    "rnd_forest_reg.fit(X_train_poly, y_train)\n",
    "\n",
    "\n",
    "# Make prediction \n",
    "y_train_predicted_rnd_forest = rnd_forest_reg.predict(X_train_poly)\n",
    "\n",
    "\n",
    "train_mse_rnd_forest = mean_squared_error(y_train, y_train_predicted_rnd_forest)\n",
    "\n",
    "print(\"Train: Mean squared error: %.2f\"\n",
    "      % train_mse_rnd_forest)\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(\"Train: Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % r2_score(y_train, y_train_predicted_rnd_forest))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_test_predicted_rnd_forest = rnd_forest_reg.predict(X_test_poly)\n",
    "\n",
    "\n",
    "test_mse_rnd_forest = mean_squared_error(y_test, y_test_predicted_rnd_forest)\n",
    "\n",
    "print(\"Test: Mean squared error: %.2f\"\n",
    "      % test_mse_rnd_forest)\n",
    "\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "\n",
    "test_r2_rnd_forest = r2_score(y_test, y_test_predicted_rnd_forest)\n",
    "\n",
    "\n",
    "print(\"Test: Coefficient of determination r^2 variance score [1 is perfect prediction]: %.2f\" \n",
    "      % test_r2_rnd_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
